{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Import packages\n",
    "import os, numpy as np, pandas as pd, time, glob, re, math, statsmodels.api as sm, patsy as ps\n",
    "from tqdm import tqdm\n",
    "from time import process_time\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "from openpyxl import load_workbook\n",
    "from patsy import dmatrices\n",
    "\n",
    "##########################################################\n",
    "##################### parameter ##########################\n",
    "##########################################################\n",
    "obj_type = '8-K'\n",
    "data_type_text = 'text_data'\n",
    "data_type_id = 'id_data'\n",
    "\n",
    "############### Set working directory to parent directory\n",
    "if os.getcwd() != 'F:\\\\github\\\\narrative_conservatism\\\\code':\n",
    "    os.chdir('F:\\\\github\\\\narrative_conservatism\\\\code')\n",
    "    \n",
    "############### Set pandas column printing constraint\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of daily obs. in CRSP: 51027516\n",
      "number of daily data in CRSP that contains only numeric returns: 50284832\n",
      "number of good news firm-days: 974962\n",
      "number of bad news firm-days: 969515\n",
      "number of total news firm-days: 1944477\n"
     ]
    }
   ],
   "source": [
    "# ########################################################################################\n",
    "# ############ Merge CRSP daily data with COMPUSTAT quarterly data #######################\n",
    "# ########################################################################################\n",
    "\n",
    "# ########### Read CRSP_daily raw data files\n",
    "# crsp_cols = ['date', 'PERMCO', 'CUSIP', 'RET', 'vwretd']\n",
    "# crsp = pd.read_csv(r'c:\\users\\fengzhi\\desktop\\crsp_daily.csv', usecols = crsp_cols, dtype={'CUSIP': str, 'RET': str})\n",
    "# crsp.columns = ['date_crsp', 'permco', 'cusip', 'ret', 'vwretd']\n",
    "\n",
    "# ### Prepare merge: create date_key\n",
    "# crsp['date_key'] = crsp['date_crsp'].astype(str)\n",
    "\n",
    "# ### Drop CRSP raw rows that contains non-numeric returns ('B' and 'C'), or with missing ret\n",
    "# print('number of daily obs. in CRSP: ' + str(crsp.shape[0]))\n",
    "# crsp = crsp[(crsp['ret'] != 'B') & (crsp['ret'] != 'C')]\n",
    "# crsp = crsp[crsp['ret'].notnull()]\n",
    "# crsp = crsp[crsp['vwretd'].notnull()] # none missing vwretd\n",
    "# print('number of daily data in CRSP that contains only numeric returns: ' + str(crsp.shape[0]))\n",
    "\n",
    "# ### Mutate adjusted daily returns RET and delete ret and vwretd\n",
    "# crsp['RET'] = crsp['ret'].astype(float) - crsp['vwretd'].astype(float)\n",
    "# crsp = crsp.drop(columns=['ret', 'vwretd'])\n",
    "\n",
    "# ### Mutate change in daily returns (comparing to last date with available ret)\n",
    "# crsp['lag_RET'] = crsp.groupby(['permco'])['RET'].shift(1)\n",
    "# crsp['DRET'] = crsp['RET'] - crsp['lag_RET']\n",
    "\n",
    "# ### calculate permco-year (py) average increase and average decrease pymean\n",
    "# crsp['cyear'] = crsp['date_crsp'].astype(str).str[:-4]\n",
    "# crsp['neg_dret'] = 0\n",
    "# crsp.loc[crsp['DRET'] <=0, ['neg_dret']] = 1\n",
    "# crsp = crsp.join(crsp.groupby(['permco', 'cyear', 'neg_dret'])['DRET'].mean().rename('pymean'), on = ['permco', 'cyear', 'neg_dret'])\n",
    "\n",
    "# ### Create good and bad news firm-day dummy\n",
    "# ### GN(BN): An indicator of good news, which takes 1 in a firm-day when the firm-day's positive (negative) RET change \\\n",
    "# ### is three times larger than the firm’s calander yearly average increase (decrease) in RET, and 0 otherwise.\n",
    "# ### NEWS: An indicator of news, which takes 1 if there is a news and 0 otherwise; NEWS = GN + BN\n",
    "# crsp['GN'] = 0\n",
    "# crsp.loc[(crsp['DRET'] > 3*crsp['pymean']) & (crsp['DRET'] >=0), ['GN']] = 1\n",
    "# crsp['BN'] = 0\n",
    "# crsp.loc[(crsp['DRET'] < 3*crsp['pymean']) & (crsp['DRET'] <0), ['BN']] = 1\n",
    "# crsp['NEWS'] = 0\n",
    "# crsp.loc[(crsp['DRET'] > 3*crsp['pymean']) & (crsp['DRET'] >=0), ['NEWS']] = 1\n",
    "# crsp.loc[(crsp['DRET'] < 3*crsp['pymean']) & (crsp['DRET'] <0), ['NEWS']] = 1\n",
    "\n",
    "# print('number of good news firm-days: ' + str((crsp['GN'] ==1).sum()))\n",
    "# print('number of bad news firm-days: ' + str((crsp['BN'] ==1).sum()))\n",
    "# print('number of total news firm-days: ' + str((crsp['NEWS'] ==1).sum()))\n",
    "\n",
    "# # crsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of quarterly filings in Compustat: 1142966\n",
      "number of quarterly filings in Compustat for merge with CRSP: 1140302\n"
     ]
    }
   ],
   "source": [
    "# ########### Read COMPUSTAT raw data files\n",
    "# comp_cols = ['gvkey', 'datadate', 'fyearq', 'fqtr', 'fyr', 'cusip', 'conm', 'actq', \\\n",
    "#              'atq', 'ceqq', 'cheq', 'cshoq', 'dlcq', 'dlttq', 'dpq', 'ibq', 'intanq', 'lctq', 'ppegtq', 'rectq', \\\n",
    "#              'revtq', 'txditcq', 'xsgaq', 'iby', 'oancfy', 'xidocy', 'exchg', 'cik', 'costat', 'prccq', 'addzip', 'incorp', 'sic', 'ipodate']\n",
    "# comp = pd.read_csv('..\\\\filings\\\\compustat.csv', usecols = comp_cols)\n",
    "\n",
    "# ### Reorder compustat column\n",
    "# # 1st line: merge keys\n",
    "# # 2nd line: extra id info\n",
    "# # 3rd line: financial data\n",
    "# # 4th line: financial data (CONT.)\n",
    "# comp = comp[['cusip', 'cik', 'datadate', \\\n",
    "# 'gvkey', 'conm', 'sic', 'incorp', 'addzip', 'fyearq', 'fqtr', 'fyr', 'ipodate', 'costat', 'exchg', \\\n",
    "# 'actq', 'atq', 'ceqq', 'cheq', 'cshoq', 'dlcq', 'dlttq', 'dpq', 'ibq', 'intanq', 'lctq', 'revtq', 'txditcq', 'xsgaq', 'oancfy', 'prccq', \\\n",
    "# 'iby', 'xidocy', 'rectq', 'ppegtq']]\n",
    "\n",
    "# print('number of quarterly filings in Compustat: ' + str(comp.shape[0]))\n",
    "\n",
    "# ### Creat lagged variables in compustat raw data\n",
    "# comp['lag_prccq'] = comp.groupby(['gvkey'])['prccq'].shift(1)\n",
    "# comp['lag_cshoq'] = comp.groupby(['gvkey'])['cshoq'].shift(1)\n",
    "# comp['lag_ceqq'] = comp.groupby(['gvkey'])['ceqq'].shift(1)\n",
    "# comp['lag_dlcq'] = comp.groupby(['gvkey'])['dlcq'].shift(1)\n",
    "# comp['lag_dlttq'] = comp.groupby(['gvkey'])['dlttq'].shift(1)\n",
    "# comp['lag_atq'] = comp.groupby(['gvkey'])['atq'].shift(1)\n",
    "# comp['lag_ibq'] = comp.groupby(['gvkey'])['ibq'].shift(1)\n",
    "# comp['lag_revtq'] = comp.groupby(['gvkey'])['revtq'].shift(1)\n",
    "# comp['lag_rectq'] = comp.groupby(['gvkey'])['rectq'].shift(1)\n",
    "# comp['lag_oancfy'] = comp.groupby(['gvkey'])['oancfy'].shift(1)\n",
    "# comp['lag_xidocy'] = comp.groupby(['gvkey'])['xidocy'].shift(1)\n",
    "\n",
    "# #####################################################################\n",
    "# ####################### Create ABTONE variables for Huang et al. 2014\n",
    "# #####################################################################\n",
    "\n",
    "# ### EARN: earnings before extraordinary items (Compustat data item ibq) scaled by lagged total assets (Compustat data item atq)\n",
    "# comp['EARN'] = comp['ibq']/comp['lag_atq']\n",
    "# ### LOSS, an indicator variable set to 1 when EARN is negative, and is 0 otherwise\n",
    "# comp['LOSS'] = 0 \n",
    "# comp.loc[comp['EARN'] < 0, 'LOSS'] = 1\n",
    "# ### DEARN: change in earnings before extraordinary item scaled by beginning total assets (Compustat data item atq)\n",
    "# comp['DEARN'] = (comp['ibq'] - comp['lag_ibq'])/comp['lag_atq']\n",
    "# ### STD_EARN: standard deviation of EARN calculated over the last five quarters\n",
    "# comp['STD_EARN'] = comp['EARN'].rolling(5).std()\n",
    "# ### CFO: quarterly operating cash flows (Compustat data item oancfy) scaled by beginning total assets (Compustat data item atq);\n",
    "# comp['CFO'] = (comp['oancfy'] - comp['lag_oancfy'])/comp['lag_atq']\n",
    "\n",
    "# # ############################################ Variables for DA calculation ###########################################\n",
    "# # ### TACC: total accruals, defined as quarterly income before extraordinary items (Compustat data item ibq) minus \\\n",
    "# # ### the difference between quarterly operating cash flows (Compustat data item oancfy) and \\\n",
    "# # ### quarterly extraordinary items and discontinued operations included in CFO (Compustat data item xidocy);\n",
    "# # comp['TACC'] = comp['ibq'] - ((comp['oancfy']-comp['lag_oancfy']) - (comp['xidocy'] - comp['lag_xidocy']))\n",
    "# # ### TA: total assets, scaled by lagged total assets (Compustat data item atq);\n",
    "# # comp['TA'] = comp['atq']/comp['lag_atq']\n",
    "# # comp['LAG_TA'] = comp.groupby(['gvkey'])['TA'].shift(1)\n",
    "# # comp['LAG_TA_REV'] = 1/comp['LAG_TA']\n",
    "# # ### DSALES: quarterly change in revenue (Compustat data item revtq), scaled by lagged total assets (Compustat data item atq);\n",
    "# # comp['DSALES'] = (comp['revtq'] - comp['lag_revtq'])/comp['lag_atq']\n",
    "# # ### DAR: quarterly change in accounts receivable (Compustat data item rectq), scaled by lagged total assets (Compustat data item atq);\n",
    "# # comp['DAR'] = (comp['rectq'] - comp['lag_rectq'])/comp['lag_atq']\n",
    "# # ### DSAR = DSALES - DAR\n",
    "# # comp['DSAR'] = comp['DSALES'] - comp['DAR']\n",
    "# # ### PPE: gross property, plant, and equipment (Compustat data item ppegtq), scaled by lagged total assets (Compustat data item atq);\n",
    "# # comp['PPE'] = comp['ppegtq']/comp['lag_atq']\n",
    "\n",
    "# #####################################################################\n",
    "# ####################################################### Prepare merge\n",
    "# #####################################################################\n",
    "\n",
    "# ### Delete the 9th digit of compustat filings' cusip, and filter filings that have 8-digits cusip after deletion \n",
    "# comp['cusip'] = comp['cusip'].astype(str).str[:-1]\n",
    "# del_cusip = comp.loc[comp['cusip'].str.len() != 8].shape[0]\n",
    "# comp = comp.loc[comp['cusip'].str.len() == 8]\n",
    "\n",
    "# ### Prepare merge: create date_key\n",
    "# comp['date_key'] = comp['datadate'].astype(str)\n",
    "\n",
    "# ### Prepare merge: drop duplicated cusip-datekey obs.\n",
    "# del_merge = comp[comp.duplicated(subset=['cusip', 'date_key'])].shape[0]\n",
    "# comp = comp[comp.duplicated(subset=['cusip', 'date_key']) == False]\n",
    "# print('number of quarterly filings in Compustat for merge with CRSP: ' + str(comp.shape[0]))\n",
    "\n",
    "# # comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of firms in CRSP: 23423\n",
      "number of firms without cik: 6698\n",
      "number of firms with unique cik: 16725\n",
      "number of obs. with missing cik before fill: 49842200\n",
      "number of obs. with missing cik after fill: 9774801\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cusip</th>\n",
       "      <th>date_key</th>\n",
       "      <th>date_crsp</th>\n",
       "      <th>RET</th>\n",
       "      <th>DRET</th>\n",
       "      <th>GN</th>\n",
       "      <th>BN</th>\n",
       "      <th>NEWS</th>\n",
       "      <th>cik</th>\n",
       "      <th>fyearq</th>\n",
       "      <th>fqtr</th>\n",
       "      <th>sic</th>\n",
       "      <th>atq</th>\n",
       "      <th>lag_atq</th>\n",
       "      <th>ceqq</th>\n",
       "      <th>lag_ceqq</th>\n",
       "      <th>lag_cshoq</th>\n",
       "      <th>lag_dlcq</th>\n",
       "      <th>lag_dlttq</th>\n",
       "      <th>lag_prccq</th>\n",
       "      <th>STD_EARN</th>\n",
       "      <th>EARN</th>\n",
       "      <th>DEARN</th>\n",
       "      <th>LOSS</th>\n",
       "      <th>STD_RET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>36720410</td>\n",
       "      <td>19930104</td>\n",
       "      <td>19930104</td>\n",
       "      <td>0.038326</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43350.0</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4924.0</td>\n",
       "      <td>28.055</td>\n",
       "      <td>26.61</td>\n",
       "      <td>9.147</td>\n",
       "      <td>7.997</td>\n",
       "      <td>1.08</td>\n",
       "      <td>3.468</td>\n",
       "      <td>8.575</td>\n",
       "      <td>14.00</td>\n",
       "      <td>0.027577</td>\n",
       "      <td>0.047351</td>\n",
       "      <td>0.018677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>36720410</td>\n",
       "      <td>19930105</td>\n",
       "      <td>19930105</td>\n",
       "      <td>-0.015765</td>\n",
       "      <td>-0.054091</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43350.0</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4924.0</td>\n",
       "      <td>28.055</td>\n",
       "      <td>26.61</td>\n",
       "      <td>9.147</td>\n",
       "      <td>7.997</td>\n",
       "      <td>1.08</td>\n",
       "      <td>3.468</td>\n",
       "      <td>8.575</td>\n",
       "      <td>14.00</td>\n",
       "      <td>0.027577</td>\n",
       "      <td>0.047351</td>\n",
       "      <td>0.018677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>36720410</td>\n",
       "      <td>19930106</td>\n",
       "      <td>19930106</td>\n",
       "      <td>-0.001458</td>\n",
       "      <td>0.014307</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43350.0</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4924.0</td>\n",
       "      <td>28.055</td>\n",
       "      <td>26.61</td>\n",
       "      <td>9.147</td>\n",
       "      <td>7.997</td>\n",
       "      <td>1.08</td>\n",
       "      <td>3.468</td>\n",
       "      <td>8.575</td>\n",
       "      <td>14.00</td>\n",
       "      <td>0.027577</td>\n",
       "      <td>0.047351</td>\n",
       "      <td>0.018677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>36720410</td>\n",
       "      <td>19930107</td>\n",
       "      <td>19930107</td>\n",
       "      <td>0.024909</td>\n",
       "      <td>0.026367</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43350.0</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4924.0</td>\n",
       "      <td>28.055</td>\n",
       "      <td>26.61</td>\n",
       "      <td>9.147</td>\n",
       "      <td>7.997</td>\n",
       "      <td>1.08</td>\n",
       "      <td>3.468</td>\n",
       "      <td>8.575</td>\n",
       "      <td>14.00</td>\n",
       "      <td>0.027577</td>\n",
       "      <td>0.047351</td>\n",
       "      <td>0.018677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>36720410</td>\n",
       "      <td>19930108</td>\n",
       "      <td>19930108</td>\n",
       "      <td>0.003884</td>\n",
       "      <td>-0.021025</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43350.0</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4924.0</td>\n",
       "      <td>28.055</td>\n",
       "      <td>26.61</td>\n",
       "      <td>9.147</td>\n",
       "      <td>7.997</td>\n",
       "      <td>1.08</td>\n",
       "      <td>3.468</td>\n",
       "      <td>8.575</td>\n",
       "      <td>14.00</td>\n",
       "      <td>0.027577</td>\n",
       "      <td>0.047351</td>\n",
       "      <td>0.018677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50284827</td>\n",
       "      <td>88160R10</td>\n",
       "      <td>20191224</td>\n",
       "      <td>20191224</td>\n",
       "      <td>0.014005</td>\n",
       "      <td>-0.018649</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1318605.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3711.0</td>\n",
       "      <td>34309.000</td>\n",
       "      <td>32795.00</td>\n",
       "      <td>6618.000</td>\n",
       "      <td>6040.000</td>\n",
       "      <td>180.00</td>\n",
       "      <td>2253.000</td>\n",
       "      <td>12383.000</td>\n",
       "      <td>240.87</td>\n",
       "      <td>0.013062</td>\n",
       "      <td>0.003202</td>\n",
       "      <td>-0.001173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50284828</td>\n",
       "      <td>88160R10</td>\n",
       "      <td>20191226</td>\n",
       "      <td>20191226</td>\n",
       "      <td>0.008762</td>\n",
       "      <td>-0.005243</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1318605.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3711.0</td>\n",
       "      <td>34309.000</td>\n",
       "      <td>32795.00</td>\n",
       "      <td>6618.000</td>\n",
       "      <td>6040.000</td>\n",
       "      <td>180.00</td>\n",
       "      <td>2253.000</td>\n",
       "      <td>12383.000</td>\n",
       "      <td>240.87</td>\n",
       "      <td>0.013062</td>\n",
       "      <td>0.003202</td>\n",
       "      <td>-0.001173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50284829</td>\n",
       "      <td>88160R10</td>\n",
       "      <td>20191227</td>\n",
       "      <td>20191227</td>\n",
       "      <td>-0.000656</td>\n",
       "      <td>-0.009418</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1318605.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3711.0</td>\n",
       "      <td>34309.000</td>\n",
       "      <td>32795.00</td>\n",
       "      <td>6618.000</td>\n",
       "      <td>6040.000</td>\n",
       "      <td>180.00</td>\n",
       "      <td>2253.000</td>\n",
       "      <td>12383.000</td>\n",
       "      <td>240.87</td>\n",
       "      <td>0.013062</td>\n",
       "      <td>0.003202</td>\n",
       "      <td>-0.001173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50284830</td>\n",
       "      <td>88160R10</td>\n",
       "      <td>20191230</td>\n",
       "      <td>20191230</td>\n",
       "      <td>-0.031325</td>\n",
       "      <td>-0.030669</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1318605.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3711.0</td>\n",
       "      <td>34309.000</td>\n",
       "      <td>32795.00</td>\n",
       "      <td>6618.000</td>\n",
       "      <td>6040.000</td>\n",
       "      <td>180.00</td>\n",
       "      <td>2253.000</td>\n",
       "      <td>12383.000</td>\n",
       "      <td>240.87</td>\n",
       "      <td>0.013062</td>\n",
       "      <td>0.003202</td>\n",
       "      <td>-0.001173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50284831</td>\n",
       "      <td>88160R10</td>\n",
       "      <td>20191231</td>\n",
       "      <td>20191231</td>\n",
       "      <td>0.005788</td>\n",
       "      <td>0.037113</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1318605.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3711.0</td>\n",
       "      <td>34309.000</td>\n",
       "      <td>32795.00</td>\n",
       "      <td>6618.000</td>\n",
       "      <td>6040.000</td>\n",
       "      <td>180.00</td>\n",
       "      <td>2253.000</td>\n",
       "      <td>12383.000</td>\n",
       "      <td>240.87</td>\n",
       "      <td>0.013062</td>\n",
       "      <td>0.003202</td>\n",
       "      <td>-0.001173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40510031 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             cusip  date_key  date_crsp       RET      DRET  GN  BN  NEWS  \\\n",
       "0         36720410  19930104   19930104  0.038326       NaN   0   0     0   \n",
       "1         36720410  19930105   19930105 -0.015765 -0.054091   0   0     0   \n",
       "2         36720410  19930106   19930106 -0.001458  0.014307   0   0     0   \n",
       "3         36720410  19930107   19930107  0.024909  0.026367   0   0     0   \n",
       "4         36720410  19930108   19930108  0.003884 -0.021025   0   0     0   \n",
       "...            ...       ...        ...       ...       ...  ..  ..   ...   \n",
       "50284827  88160R10  20191224   20191224  0.014005 -0.018649   0   0     0   \n",
       "50284828  88160R10  20191226   20191226  0.008762 -0.005243   0   0     0   \n",
       "50284829  88160R10  20191227   20191227 -0.000656 -0.009418   0   0     0   \n",
       "50284830  88160R10  20191230   20191230 -0.031325 -0.030669   0   0     0   \n",
       "50284831  88160R10  20191231   20191231  0.005788  0.037113   0   0     0   \n",
       "\n",
       "                cik  fyearq  fqtr     sic        atq   lag_atq      ceqq  \\\n",
       "0           43350.0  1993.0   3.0  4924.0     28.055     26.61     9.147   \n",
       "1           43350.0  1993.0   3.0  4924.0     28.055     26.61     9.147   \n",
       "2           43350.0  1993.0   3.0  4924.0     28.055     26.61     9.147   \n",
       "3           43350.0  1993.0   3.0  4924.0     28.055     26.61     9.147   \n",
       "4           43350.0  1993.0   3.0  4924.0     28.055     26.61     9.147   \n",
       "...             ...     ...   ...     ...        ...       ...       ...   \n",
       "50284827  1318605.0  2019.0   4.0  3711.0  34309.000  32795.00  6618.000   \n",
       "50284828  1318605.0  2019.0   4.0  3711.0  34309.000  32795.00  6618.000   \n",
       "50284829  1318605.0  2019.0   4.0  3711.0  34309.000  32795.00  6618.000   \n",
       "50284830  1318605.0  2019.0   4.0  3711.0  34309.000  32795.00  6618.000   \n",
       "50284831  1318605.0  2019.0   4.0  3711.0  34309.000  32795.00  6618.000   \n",
       "\n",
       "          lag_ceqq  lag_cshoq  lag_dlcq  lag_dlttq  lag_prccq  STD_EARN  \\\n",
       "0            7.997       1.08     3.468      8.575      14.00  0.027577   \n",
       "1            7.997       1.08     3.468      8.575      14.00  0.027577   \n",
       "2            7.997       1.08     3.468      8.575      14.00  0.027577   \n",
       "3            7.997       1.08     3.468      8.575      14.00  0.027577   \n",
       "4            7.997       1.08     3.468      8.575      14.00  0.027577   \n",
       "...            ...        ...       ...        ...        ...       ...   \n",
       "50284827  6040.000     180.00  2253.000  12383.000     240.87  0.013062   \n",
       "50284828  6040.000     180.00  2253.000  12383.000     240.87  0.013062   \n",
       "50284829  6040.000     180.00  2253.000  12383.000     240.87  0.013062   \n",
       "50284830  6040.000     180.00  2253.000  12383.000     240.87  0.013062   \n",
       "50284831  6040.000     180.00  2253.000  12383.000     240.87  0.013062   \n",
       "\n",
       "              EARN     DEARN  LOSS   STD_RET  \n",
       "0         0.047351  0.018677   0.0  0.021425  \n",
       "1         0.047351  0.018677   0.0  0.021425  \n",
       "2         0.047351  0.018677   0.0  0.021425  \n",
       "3         0.047351  0.018677   0.0  0.021425  \n",
       "4         0.047351  0.018677   0.0  0.021425  \n",
       "...            ...       ...   ...       ...  \n",
       "50284827  0.003202 -0.001173   0.0  0.031451  \n",
       "50284828  0.003202 -0.001173   0.0  0.031451  \n",
       "50284829  0.003202 -0.001173   0.0  0.031451  \n",
       "50284830  0.003202 -0.001173   0.0  0.031451  \n",
       "50284831  0.003202 -0.001173   0.0  0.031451  \n",
       "\n",
       "[40510031 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ############################################# Merge: CRSP and COMP\n",
    "# crsp_comp = crsp[['cusip', 'date_key', \\\n",
    "#                   'date_crsp', 'RET', 'DRET','GN', 'BN', 'NEWS']]\n",
    "# ################# Delete CRSP to save memory\n",
    "# del crsp \n",
    "\n",
    "# ##################### Left merge CRSP and COMPUSTAT, key unique in both datasets\n",
    "# comp_cols = ['cusip', 'date_key', \\\n",
    "#              'cik', 'fyearq', 'fqtr', 'sic', \\\n",
    "#              'atq', 'lag_atq', 'ceqq', 'lag_ceqq', 'lag_cshoq', 'lag_dlcq', 'lag_dlttq', 'lag_prccq', \\\n",
    "#              'STD_EARN', 'EARN', 'DEARN', 'LOSS']\n",
    "\n",
    "# crsp_comp = pd.merge(crsp_comp, comp[comp_cols], on = ['cusip', 'date_key'], how='left', validate = '1:1')\n",
    "\n",
    "# ################# Delete CRSP to save memory\n",
    "# del comp\n",
    "\n",
    "# ###### After merging, count number of firms (identified by cusip) that has unique cik\n",
    "# print('total number of firms in CRSP: ' + str((crsp_comp.groupby(['cusip'])['cik'].nunique()).shape[0]))\n",
    "# print('number of firms without cik: ' + str((crsp_comp.groupby(['cusip'])['cik'].nunique() == 0).sum()))\n",
    "# print('number of firms with unique cik: ' + str((crsp_comp.groupby(['cusip'])['cik'].nunique() == 1).sum()))\n",
    "\n",
    "# ###### Fill cik with first and last observed non-null value by cusip group ########### Takes some time!!\n",
    "# print('number of obs. with missing cik before fill: ' + str(crsp_comp['cik'].isnull().sum()))\n",
    "# crsp_comp['cik'] = crsp_comp.groupby(['cusip'])['cik'].fillna(method='ffill')\n",
    "# crsp_comp['cik'] = crsp_comp.groupby(['cusip'])['cik'].fillna(method='bfill')\n",
    "# print('number of obs. with missing cik after fill: ' + str(crsp_comp['cik'].isnull().sum()))\n",
    "# # print('number of firms with n cik: ' + str((crsp_comp.groupby(['cusip'])['cik'].nunique() == n).sum()))\n",
    "\n",
    "# ###### Drop obs. without cik\n",
    "# crsp_comp = crsp_comp[crsp_comp['cik'].notnull()]\n",
    "\n",
    "# ###### Backward fill financial variables with last observed non-null value by cik group (now equal to cusip group)\n",
    "# def bfill (df, groupby, colnames):\n",
    "#     for col in colnames:\n",
    "#         df[col] = df.groupby(groupby)[col].fillna(method='bfill')\n",
    "#     return df\n",
    "\n",
    "# comp_cols.remove('date_key')\n",
    "# comp_cols.remove('cusip')\n",
    "# comp_cols.remove('cik')\n",
    "\n",
    "# groupcols = ['cik']\n",
    "\n",
    "# crsp_comp = bfill(crsp_comp, groupcols, comp_cols)\n",
    "\n",
    "# #################### STD_RET: standard deviation of RET over current fiscal quarter\n",
    "# crsp_comp = crsp_comp.join(crsp_comp.groupby(['cik', 'fyearq', 'fqtr'])['RET'].std().rename('STD_RET'), on = ['cik', 'fyearq', 'fqtr'])\n",
    "\n",
    "# ###### Inspect missing values for CRSP_COMP\n",
    "# # print(crsp_comp.isnull().sum())\n",
    "\n",
    "# ############## Save merged CRSP_COMP dataframe into local file crsp_comp_10-Q.csv (8.28GB: too big for Github, therefore stored in desktop)\n",
    "# crsp_comp.to_csv(r'c:\\users\\fengzhi\\desktop\\crsp_comp_' + obj_type + '.csv', index = 0)\n",
    "\n",
    "# crsp_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########################################################################################\n",
    "# ####### Concatenate and prepare merge: from ID_DATA and TEXT_DATA to EDGAR #############\n",
    "# ########################################################################################\n",
    "\n",
    "# ############## Define a function to concatenate all csv files with file name that matches a certain pattern into one data frame\n",
    "# def concatenate (indir, file_name_match):\n",
    "#     os.chdir(indir)\n",
    "#     file_list = glob.glob(file_name_match)\n",
    "#     df_list = list()\n",
    "#     colnames = pd.read_csv(file_list[0], header = None).loc[0]\n",
    "    \n",
    "#     for filename in file_list:\n",
    "#         # print(filename)\n",
    "#         df = pd.read_csv(filename, low_memory = False)\n",
    "#         df_list.append(df)\n",
    "\n",
    "#     df_concat = pd.concat(df_list, axis = 0)\n",
    "#     df_concat.columns = colnames\n",
    "#     return df_concat\n",
    "\n",
    "# ############## Concatenate id_data and text_data files and create two data frames\n",
    "# id_data = concatenate('..\\\\filings', data_type_id + '_'+ obj_type + '_' + '*.csv')\n",
    "# text_data = concatenate('..\\\\filings', data_type_text + '_'+ obj_type + '_' + '*.csv')\n",
    "\n",
    "# ############## Save id_data dataframe into local file id_data_8-K.csv\n",
    "# id_data.to_csv('..\\\\filings\\\\' + data_type_id + '_'+ obj_type + '.csv', index = 0)\n",
    "\n",
    "# ############################################################\n",
    "# #################################### text_data modifications\n",
    "# ############################################################\n",
    "\n",
    "# ############## Correct modal words labels in text_data\n",
    "# text_data.columns = ['accnum', 'nw', 'nvocab', 'n_neg', 'n_pos', 'n_uctt', 'n_lit', 'n_cstr', \\\n",
    "#                      'n_modal_strong', 'n_modal_moderate', 'n_modal_weak', 'n_negation']\n",
    "\n",
    "# ############## Save text_data dataframe into local file text_data_8-K.csv\n",
    "# text_data.to_csv('..\\\\filings\\\\' + data_type_text + '_'+ obj_type + '.csv', index = 0)\n",
    "\n",
    "# print('Number of ' + obj_type + ' in edgar from 1993 Q1 to 2020 Q1: ' + str(id_data.shape[0]))\n",
    "# print('Number of ' + obj_type + ' parsed and downloaded: ' + str(text_data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########################################################################################\n",
    "# ######################## Merge ID_DATA with TEXT_DATA into EDGAR #######################\n",
    "# ########################################################################################\n",
    "\n",
    "# # id_data = concatenate('..\\\\filings', data_type_id + '_'+ obj_type + '_' + '*.csv')\n",
    "\n",
    "# ############## Prepare merge: ID_DATA\n",
    "# id_data['fd'] = id_data['fd'].str.replace('-', '')\n",
    "# id_data['rp'] = id_data['rp'].str.replace('-', '')\n",
    "# id_data['date_key'] = id_data['rp'].astype(str)\n",
    "\n",
    "# ############## Drop unnecessary columns and reorder id_data\n",
    "# id_data = id_data.drop(columns=['file_type', 'sic', 'fye', 'bazip', 'state'])\n",
    "# id_data = id_data[['cik', 'rp', 'fd', 'accnum', 'item8k', 'name', 'date_key']].sort_values(by = ['cik', 'rp'])\n",
    "\n",
    "# ############## Drop 8-Ks that has duplicated accnum and cik-rp\n",
    "# del_accnum = id_data[id_data.duplicated('accnum')].shape[0]\n",
    "# id_data = id_data[id_data.duplicated('accnum') == False]\n",
    "# del_cik_rp = id_data[id_data.duplicated(subset=['cik', 'rp','item8k'])].shape[0]\n",
    "# id_data = id_data[id_data.duplicated(subset=['cik', 'rp','item8k']) == False]\n",
    "# print('Number of ' + obj_type + ' with duplicated accnum and cik-rp-item8k: ' + str(del_accnum + del_cik_rp))\n",
    "\n",
    "# ############## Drop 8-Ks without items\n",
    "# del_item8k = id_data[id_data['item8k'].isnull()].shape[0]\n",
    "# id_data = id_data[id_data['item8k'].notnull()]\n",
    "# print('Number of ' + obj_type + ' with missing items8k: ' + str(del_item8k))\n",
    "\n",
    "# ############## Drop 8-Ks with reporting period larger than filing date\n",
    "# del_rp_fd = id_data[id_data['rp'].astype(int) > id_data['fd'].astype(int)].shape[0]\n",
    "# id_data = id_data[id_data['rp'].astype(int) <= id_data['fd'].astype(int)]\n",
    "# print('Number of ' + obj_type + ' with reporting period larger than filing date: ' + str(del_rp_fd))\n",
    "\n",
    "# print('Number of remaining ' + obj_type + ' with after screening: ' + str(id_data.shape[0]))\n",
    "\n",
    "# ############## Count number of 8k per cik-day\n",
    "# id_data = id_data.join(id_data.groupby(['cik', 'rp']).size().rename('n8k'), on=['cik', 'rp'])\n",
    "\n",
    "# ##############################################################################\n",
    "# ############################ Disaggregate item8K into separate count variables\n",
    "# ##############################################################################\n",
    "\n",
    "# id_data_before2004 = id_data[id_data['fd'].astype(int) < 20040823]\n",
    "# id_data_after2004 = id_data[id_data['fd'].astype(int) >= 20040823]\n",
    "\n",
    "# def count_item_occurances (df, item):\n",
    "#     for i in item:\n",
    "#         df.loc[:,'item_' + i] = df.groupby(['cik', 'rp'])['item8k'].transform(lambda x: x[x.str.contains(i)].count())\n",
    "#     return df\n",
    "\n",
    "# item_before2004 = ['1','2','3','4','5','6','7','8','9','10','11','12']\n",
    "# item_after2004 = ['1.01','1.02','1.03','1.04', \\\n",
    "#                   '2.01','2.02','2.03','2.04','2.05','2.06', \\\n",
    "#                   '3.01','3.02','3.03', \\\n",
    "#                   '4.01','4.02',\n",
    "#                   '5.01','5.02','5.03','5.04','5.05','5.06','5.07','5.08', \\\n",
    "#                   '6.01','6.02','6.03','6.04','6.05', \\\n",
    "#                   '7.01', \\\n",
    "#                   '8.01', \\\n",
    "#                   '9.01']\n",
    "\n",
    "# ########################################################################################### Roughly takes 7 hours!!\n",
    "# id_data_before2004 = count_item_occurances(id_data_before2004, item_before2004)\n",
    "\n",
    "# for i in item_after2004:\n",
    "#     id_data_before2004.loc[:,'item_' + i] = 0\n",
    "\n",
    "# for i in item_before2004:\n",
    "#     id_data_after2004.loc[:,'item_' + i] = 0\n",
    "    \n",
    "# id_data_after2004 = count_item_occurances(id_data_after2004, item_after2004)\n",
    "# ########################################################################################## Roughly takes 7 hours!!\n",
    "\n",
    "# ############################ Concatenate id_data_before2004 and id_data_after2004\n",
    "# id_data = pd.concat([id_data_before2004, id_data_after2004]).sort_values(by = ['cik', 'rp'])\n",
    "\n",
    "# ##############################################################################\n",
    "# ########################################## Merge id_data_8-K and text_data_8-K\n",
    "# ##############################################################################\n",
    "\n",
    "# ########## Merge id_data and text_data by accnum\n",
    "# edgar = pd.merge(id_data, text_data, on = ['accnum'], how = 'inner', validate = '1:1')\n",
    "\n",
    "# ########## Sum up text count by cik-rp\n",
    "# text_count_vars = ['nw', 'nvocab', 'n_neg', 'n_pos', 'n_uctt', 'n_lit', 'n_cstr', \\\n",
    "#               'n_modal_strong', 'n_modal_moderate', 'n_modal_weak', 'n_negation']\n",
    "# edgar_daily = edgar.groupby(['cik','rp'])[text_count_vars].sum()\n",
    "# edgar_daily.columns = text_count_vars\n",
    "# edgar = edgar.drop(columns = text_count_vars)\n",
    "# edgar = edgar.join(edgar_daily, on=['cik', 'rp'])\n",
    "\n",
    "# ############## Calculate tone : tone = (n_pos - n_negation - n_neg)/nw\n",
    "# edgar['tone'] = (edgar['n_pos'] - edgar['n_negation'] - edgar['n_neg'])/edgar['nw']\n",
    "\n",
    "# ########## Drop duplicate cik-rp\n",
    "# edgar = edgar[edgar.duplicated(subset=['cik', 'rp']) == False]\n",
    "\n",
    "# ############### Save processed EDGAR to local edgar_8-K.csv ########################\n",
    "# edgar.to_csv('..\\\\filings\\\\edgar_'+ obj_type + '.csv', index = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########################################################################################\n",
    "# ################## Merge EDGAR with CRSP_COMPUSTAT: MATCH PROCESS ######################\n",
    "# ########################################################################################\n",
    "\n",
    "# ########## Load CRSP_COMP dataset\n",
    "# crsp_comp_cols = ['date_crsp', 'cusip', 'cik', 'RET', 'DRET', 'GN', 'BN', 'NEWS', 'date_key']\n",
    "# crsp_comp = pd.read_csv(r'c:\\users\\fengzhi\\desktop\\crsp_comp_' + obj_type + '.csv', \\\n",
    "#                         usecols = crsp_comp_cols, dtype = {'cik': str, 'cusip': str, 'date_key': str})\n",
    "\n",
    "# ### Delete last two digits (.0) of crsp_comp['cik'] \n",
    "# crsp_comp['cik'] = crsp_comp['cik'].astype(str).str[:-2]\n",
    "# crsp_comp['match_crsp_comp'] = float('nan')\n",
    "\n",
    "# ### Sort CRSP_COMP by cik-date_key in order to match NEWS and EDGAR later\n",
    "# crsp_comp = crsp_comp.sort_values(by = ['cik', 'date_key'])\n",
    "\n",
    "# ########## Load EDGAR dataset\n",
    "# edgar_cols = ['cik', 'rp', 'fd', 'item8k', 'name', 'date_key', 'n8k', 'nw', 'nvocab', 'n_neg', 'n_pos', 'n_negation', 'tone']\n",
    "# edgar = pd.read_csv('..\\\\filings\\\\edgar_8-K.csv', usecols = edgar_cols, dtype = {'cik': str, 'date_key': str})\n",
    "\n",
    "# ### Sort CRSP_COMP by cik-date_key in order to match NEWS and EDGAR later\n",
    "# edgar = edgar.sort_values(by = ['cik', 'date_key'])\n",
    "# edgar['match_edgar'] = edgar.index\n",
    "\n",
    "# ############## Left merge CRSP_COMP and EDGAR, key unique in both data sets\n",
    "# crsp_comp_edgar = pd.merge(crsp_comp, edgar, on = ['cik', 'date_key'], how = 'left', validate = '1:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 894088/894088 [30:20:49<00:00,  8.18it/s]\n"
     ]
    }
   ],
   "source": [
    "# ############### Match every firm-day that has reported 8-K to its first precedent (or same) NEWS firm-day \n",
    "# ############### if there are more than one 8-K firm-day between two consecutive NEWS firm-day, match to the first 8-K firm-day.\n",
    "\n",
    "# match_edgar_idx = crsp_comp_edgar.columns.get_loc('match_edgar')\n",
    "# match_crsp_comp_idx = crsp_comp_edgar.columns.get_loc('match_crsp_comp')\n",
    "# NEWS_idx = crsp_comp_edgar.columns.get_loc('NEWS')\n",
    "# eight_k_day_idx = crsp_comp_edgar[crsp_comp_edgar['rp'].notnull()].index #[:20]\n",
    "\n",
    "# #################################################################################################### Takes 30 hours!!\n",
    "# for idx in tqdm(eight_k_day_idx):\n",
    "#     idx_match = idx\n",
    "#     while crsp_comp_edgar.iloc[idx, NEWS_idx] == 0:\n",
    "#         idx -= 1\n",
    "#     else:\n",
    "#         if math.isnan(crsp_comp_edgar.iloc[idx, match_crsp_comp_idx]) == True:\n",
    "#             crsp_comp_edgar.iloc[idx, match_crsp_comp_idx] = crsp_comp_edgar.iloc[idx_match, match_edgar_idx]\n",
    "# #################################################################################################### Takes 30 hours!!\n",
    "\n",
    "# ############### Create new CRSP_COMP based on matched CRSP_COMP_EDGAR\n",
    "# crsp_comp = crsp_comp_edgar[['date_crsp', 'cik', 'cusip', 'RET', 'DRET', 'GN', 'BN', 'NEWS', 'match_crsp_comp']]\n",
    "# crsp_comp = crsp_comp.rename(columns={'match_crsp_comp': 'match'})\n",
    "# crsp_comp = crsp_comp[crsp_comp['match'].notnull()]\n",
    "\n",
    "# ############### Create new EDGAR based on matched CRSP_COMP_EDGAR by changing matched_key name \n",
    "# edgar = edgar.rename(columns={'match_edgar': 'match'})\n",
    "\n",
    "# ############### Merge into CRSP_COMP_EDGAR_MATCHED dataframe\n",
    "# crsp_comp_edgar = pd.merge(crsp_comp, edgar, on = ['match'], how = 'inner', validate = '1:1')\n",
    "\n",
    "# #### Drop NEWS-8K matches of different CIKs\n",
    "# del_cik_match = crsp_comp_edgar[crsp_comp_edgar['cik_x'] != crsp_comp_edgar['cik_y']].shape[0]\n",
    "# print('number of obs. with different cik: ' + str(del_cik_match))\n",
    "# crsp_comp_edgar = crsp_comp_edgar[crsp_comp_edgar['cik_x'] == crsp_comp_edgar['cik_y']]\n",
    "\n",
    "# ############ Save machted CRSP_COMP_EDGAR to local crsp_comp_edgar_8-K_matched.csv ########################\n",
    "# crsp_comp_edgar.to_csv('..\\\\filings\\\\crsp_comp_edgar_'+ obj_type + '_matched.csv', index = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of obs. in CRSP_COMP_EDGAR after merging: 390698\n"
     ]
    }
   ],
   "source": [
    "########################################################################################\n",
    "############## Add financial variables from CRSP_COMP to CRSP_COMP_EDGAR ###############\n",
    "########################################################################################\n",
    "\n",
    "############### Load processed CRSP_COMP_EDGAR_MATCHED\n",
    "crsp_comp_edgar_cols = ['date_crsp', 'cik_x', 'cusip', 'RET', 'DRET', 'GN', 'BN', 'NEWS', \\\n",
    "                        'rp', 'fd', 'item8k', 'name', 'n8k', 'nw', 'nvocab', 'n_neg', 'n_pos', 'n_negation', 'tone']\n",
    "crsp_comp_edgar_matched = pd.read_csv(r'..\\filings\\crsp_comp_edgar_' + obj_type + '_matched.csv', usecols = crsp_comp_edgar_cols, \\\n",
    "                              dtype={'cik_x': str, 'cusip': str})\n",
    "\n",
    "############### Load processed CRSP_COMP\n",
    "crsp_comp_cols = ['cusip', 'date_crsp', \\\n",
    "                  'fyearq', 'sic', \\\n",
    "                  'atq', 'lag_atq', 'ceqq', 'lag_ceqq', 'lag_cshoq', 'lag_dlcq', 'lag_dlttq', 'lag_prccq', \\\n",
    "                  'STD_EARN', 'EARN', 'DEARN', 'LOSS', 'STD_RET']\n",
    "crsp_comp = pd.read_csv(r'c:\\users\\fengzhi\\desktop\\crsp_comp_' + obj_type + '.csv', usecols = crsp_comp_cols, \\\n",
    "                              dtype={'cusip': str})\n",
    "\n",
    "############## Add financial variables from CRSP_COMP to CRSP_COMP_EDGAR by merging\n",
    "crsp_comp_edgar = pd.merge(crsp_comp_edgar_matched, crsp_comp, on = ['cusip', 'date_crsp'], how = 'left', validate = '1:1')\n",
    "\n",
    "############## Rename cik, and drop (actually no duplicates to drop) duplicated rows in [cik * date_crsp] and [cik * rp], and match \n",
    "crsp_comp_edgar = crsp_comp_edgar.rename(columns={'cik_x': 'cik', 'sic': 'SIC'})\n",
    "# crsp_comp_edgar = crsp_comp_edgar[crsp_comp_edgar.duplicated('match') == False]\n",
    "# crsp_comp_edgar = crsp_comp_edgar[crsp_comp_edgar.duplicated(subset=['cik', 'rp']) == False]\n",
    "# crsp_comp_edgar = crsp_comp_edgar[crsp_comp_edgar.duplicated(subset=['cik', 'date_crsp']) == False]\n",
    "\n",
    "# Delete crsp_comp and crsp_comp_edgar_matched to release memory\n",
    "del crsp_comp, crsp_comp_edgar_matched\n",
    "\n",
    "############## Create filing date year-quarter fixed effects identifier cquarter\n",
    "crsp_comp_edgar['cmonth'] = crsp_comp_edgar['fd'].astype(str).str[:-2]\n",
    "\n",
    "############# Reorder crsp_comp_edgar columns\n",
    "# 1st line: merge keys\n",
    "# 2nd line: extra id info\n",
    "# 3th line: financial raw data (lagged variables)\n",
    "# 4th line: text variables\n",
    "# 5th line: ready-to-use regression variables\n",
    "crsp_comp_edgar = crsp_comp_edgar[['cusip', 'date_crsp', 'cik', 'rp', \\\n",
    "                                   'name', 'SIC', 'fd', 'cmonth', 'fyearq', \\\n",
    "                                   'atq', 'lag_atq', 'ceqq', 'lag_ceqq', 'lag_cshoq', 'lag_dlcq', 'lag_dlttq', 'lag_prccq', \\\n",
    "                                   'item8k', 'n8k', 'nw', 'nvocab', 'n_neg', 'n_pos', 'n_negation', 'tone', \\\n",
    "                                   'RET', 'DRET', 'STD_RET', 'EARN', 'LOSS', 'DEARN', 'STD_EARN', 'BN']]\n",
    "\n",
    "print('Number of obs. in CRSP_COMP_EDGAR after merging: ' + str(crsp_comp_edgar.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of obs. with missing SIC: 13982\n"
     ]
    }
   ],
   "source": [
    "####################### Modify data type in ID_CRSP_COMP_TEXT\n",
    "########### Define a function that changes pandas series data type to string\n",
    "def columns_to_str (df, colnames):\n",
    "    for col in colnames:\n",
    "        df[col] = df[col].astype(str)\n",
    "    return df\n",
    "\n",
    "########### Apply columns_to_str to various identification variables\n",
    "crsp_comp_edgar = columns_to_str(crsp_comp_edgar, ['cik', 'cusip', 'fyearq'])\n",
    "\n",
    "########## Convert date variables to date format\n",
    "crsp_comp_edgar['date_crsp'] = pd.to_datetime(crsp_comp_edgar['date_crsp'], format='%Y%m%d')\n",
    "crsp_comp_edgar['fd'] = pd.to_datetime(crsp_comp_edgar['fd'], format='%Y%m%d')\n",
    "crsp_comp_edgar['rp'] = pd.to_datetime(crsp_comp_edgar['rp'], format='%Y%m%d')\n",
    "\n",
    "############## Drop obs. with missing SIC and convert SIC variables to integer\n",
    "del_sic = crsp_comp_edgar[crsp_comp_edgar['SIC'].isnull()].shape[0]\n",
    "crsp_comp_edgar = crsp_comp_edgar[crsp_comp_edgar['SIC'].notnull()]\n",
    "print('Number of obs. with missing SIC: ' + str(del_sic))\n",
    "\n",
    "crsp_comp_edgar['SIC'] = crsp_comp_edgar['SIC'].astype(int)\n",
    "\n",
    "########### Inspect column data types\n",
    "# print(crsp_comp_edgar.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of obs. with beginning common share price less than $1: 14109\n",
      "Number of obs. with non-positive common shares outstanding: 80\n"
     ]
    }
   ],
   "source": [
    "########################################################################################\n",
    "############################### Variable Creation ######################################\n",
    "########################################################################################\n",
    "\n",
    "############################## Main Variables ##########################################\n",
    "######## NW: natural log of 1 + total number of words in the document\n",
    "crsp_comp_edgar['NW'] = np.log(1 + crsp_comp_edgar['nw'])\n",
    "\n",
    "######## TONE: number of net positive words (n_pos - n_neg - n_negations) per 1000 total words\n",
    "crsp_comp_edgar['TONE'] = crsp_comp_edgar['tone']*1000\n",
    "\n",
    "######## TLAG: Time lag between the news release date (CRSP date) and document filing date (EDGAR filing date)\n",
    "crsp_comp_edgar['TLAG'] = (crsp_comp_edgar['fd'] - crsp_comp_edgar['date_crsp']).dt.days\n",
    "\n",
    "### BN: An indicator of bad news, which takes 1 in a firm-day when the firm-day's negative RET change \\\n",
    "### is three times larger than the firm’s current calander-yearly average decrease in RET, and 0 if there is good news.\n",
    "\n",
    "############## Drop obs. with [beginning-of-quarter] common share price less than $1\n",
    "del_prccq = crsp_comp_edgar.loc[(crsp_comp_edgar['lag_prccq'] < 1) | (crsp_comp_edgar['lag_prccq'].isnull())].shape[0]\n",
    "crsp_comp_edgar = crsp_comp_edgar.loc[crsp_comp_edgar['lag_prccq'] >= 1]\n",
    "print('Number of obs. with beginning common share price less than $1: ' + str(del_prccq))\n",
    "\n",
    "############## Drop obs. with [beginning-of-quarter] non-positive common shares outstanding\n",
    "del_cshoq = crsp_comp_edgar.loc[(crsp_comp_edgar['lag_cshoq'] == 0) | (crsp_comp_edgar['lag_cshoq'].isnull())].shape[0]\n",
    "crsp_comp_edgar = crsp_comp_edgar.loc[crsp_comp_edgar['lag_cshoq'] > 0]\n",
    "print('Number of obs. with non-positive common shares outstanding: ' + str(del_cshoq))\n",
    "\n",
    "############################## Control Variables #######################################\n",
    "######## Size: Firm size, defined as the natural logarithm of market value of equity [at the beginning of the quarter] \\\n",
    "######## defined as [beginning-of-quarter] common share price (Compustat data item prccq) \\\n",
    "######## times [beginning-of-quarter] common shares outstanding (Compustat data item cshoq)\n",
    "crsp_comp_edgar['SIZE'] = np.log(crsp_comp_edgar['lag_prccq']*crsp_comp_edgar['lag_cshoq'])\n",
    "\n",
    "######## MTB: Market-to-book ratio, defined as [beginning-of-quarter] market value of equity \\\n",
    "######## defined as common share price (Compustat data item prccq) times common shares outstanding (Compustat data item cshoq) \\\n",
    "######## divided by [beginning-of-quarter] book value of equity (Compustat data item ceqq) \n",
    "crsp_comp_edgar['MTB'] = (crsp_comp_edgar['lag_prccq']*crsp_comp_edgar['lag_cshoq'])/crsp_comp_edgar['lag_ceqq']\n",
    "\n",
    "######## LEV: Leverage, defined as [beginning-of-quarter] short term debt plus [beginning-of-quarter] long term debt \\\n",
    "######## (Compustat data item dlcq + Compustat data item dlttq) scaled by [beginning-of-quarter] total assets (Compustat data item atq)\n",
    "crsp_comp_edgar['LEV'] = (crsp_comp_edgar['lag_dlcq'] + crsp_comp_edgar['lag_dlttq'])/crsp_comp_edgar['lag_atq']\n",
    "\n",
    "# ######## AGE: log(1 + age from the first year the firm entered the CRSP dataset)\n",
    "# id_crsp_comp_text['AGE'] = np.log(1 + id_crsp_comp_text['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of obs. from utility and financial firms: 97842\n",
      "number of firm-quarters with missing SIC, SIZE, MTB, LEV or non-positive (total assets or book value of equity or common shares outstanding), or lag_prcc < 1: 43573\n",
      "number of words, 1% quantile: 133.0\n",
      "number of obs. that contain total words less than 1% threshold: 2427\n",
      "number of obs. that contain negative TLAG: 0\n",
      "TLAG 99% quantile: 142.0\n",
      "number of obs. that contain negative or larger than 99% TLAG: 2455\n",
      "Number of obs. after variable screening: 244401\n"
     ]
    }
   ],
   "source": [
    "########################################################################################\n",
    "############################### Variable Screening #####################################\n",
    "########################################################################################\n",
    "\n",
    "############## Drop financial and utility firms (SIC codes between 6000 and 6999 and between 4900 and 4999, respectively)\n",
    "del_fin = crsp_comp_edgar.loc[(crsp_comp_edgar['SIC'] >= 6000) & (crsp_comp_edgar['SIC'] <= 6999)].shape[0]\n",
    "crsp_comp_edgar = crsp_comp_edgar.loc[(crsp_comp_edgar['SIC'] < 6000) | (crsp_comp_edgar['SIC'] > 6999)] # financial\n",
    "del_ut = crsp_comp_edgar.loc[(crsp_comp_edgar['SIC'] >= 4900) & (crsp_comp_edgar['SIC'] <= 4999)].shape[0]\n",
    "crsp_comp_edgar = crsp_comp_edgar.loc[(crsp_comp_edgar['SIC'] < 4900) | (crsp_comp_edgar['SIC'] > 4999)] # utility\n",
    "print('number of obs. from utility and financial firms: ' + str(del_fin + del_ut))\n",
    "\n",
    "############## Drop files (firm-quarter) that have missing SIC, SIZE, MTB, LEV, or with non-positive total assets or book value of equity\n",
    "del_size = crsp_comp_edgar[crsp_comp_edgar['SIZE'].isnull()].shape[0]\n",
    "crsp_comp_edgar = crsp_comp_edgar[crsp_comp_edgar['SIZE'].notnull()]\n",
    "del_mtb = crsp_comp_edgar[crsp_comp_edgar['MTB'].isnull()].shape[0]\n",
    "crsp_comp_edgar = crsp_comp_edgar[crsp_comp_edgar['MTB'].notnull()]\n",
    "del_lev = crsp_comp_edgar[crsp_comp_edgar['LEV'].isnull()].shape[0]\n",
    "crsp_comp_edgar = crsp_comp_edgar[crsp_comp_edgar['LEV'].notnull()]\n",
    "del_atq = crsp_comp_edgar.loc[(crsp_comp_edgar['atq'] <= 0) | (crsp_comp_edgar['atq'].isnull())].shape[0]\n",
    "crsp_comp_edgar = crsp_comp_edgar.loc[crsp_comp_edgar['atq'] > 0]\n",
    "del_ceqq = crsp_comp_edgar.loc[(crsp_comp_edgar['ceqq'] <= 0) | (crsp_comp_edgar['ceqq'].isnull())].shape[0]\n",
    "crsp_comp_edgar = crsp_comp_edgar.loc[crsp_comp_edgar['ceqq'] > 0]\n",
    "print('number of firm-quarters with missing SIC, SIZE, MTB, LEV or non-positive (total assets or book value of equity or common shares outstanding), or lag_prcc < 1: ' \\\n",
    "      + str(del_sic + del_size + del_mtb + del_lev + del_atq + del_ceqq + del_prccq + del_cshoq))\n",
    "\n",
    "########## Drop files (firm-quarter) that contain number of words less than 1% threshold (or larger than 99% threshold)\n",
    "nwq01 = crsp_comp_edgar['nw'].quantile(.01)\n",
    "print('number of words, 1% quantile: ' + str(nwq01))\n",
    "del_word01 = crsp_comp_edgar.loc[crsp_comp_edgar['nw'] < nwq01].shape[0]\n",
    "print('number of obs. that contain total words less than 1% threshold: ' + str(del_word01))\n",
    "crsp_comp_edgar = crsp_comp_edgar.loc[crsp_comp_edgar['nw'] >= nwq01]\n",
    "\n",
    "# nwq99 = crsp_comp_edgar['nw'].quantile(.99)\n",
    "# print('number of words, 99% quantile: ' + str(nwq99))\n",
    "# del_word99 = crsp_comp_edgar.loc[crsp_comp_edgar['nw'] > nwq99].shape[0]\n",
    "# print('number of obs. that contain total words more than 99% threshold: ' + str(del_word99))\n",
    "# crsp_comp_edgar = crsp_comp_edgar.loc[crsp_comp_edgar['nw'] <= nwq99]\n",
    "\n",
    "########## Drop files (firm-quarter) that contain negative TLAG\n",
    "# Rationale to drop negative TLAG: By construction, filings with filing date prior to news release date cannot be addressing the news. \n",
    "# ANTICIPATION is not purpose of the paper.\n",
    "del_TLAG0 = crsp_comp_edgar[crsp_comp_edgar['TLAG'] < 0].shape[0]\n",
    "print('number of obs. that contain negative TLAG: ' + str(del_TLAG0))\n",
    "crsp_comp_edgar = crsp_comp_edgar[crsp_comp_edgar['TLAG'] >= 0]\n",
    "\n",
    "########## Drop files (firm-quarter) that contain larger than 99% TLAG\n",
    "tlagq99 = crsp_comp_edgar['TLAG'].quantile(.99)\n",
    "print('TLAG 99% quantile: ' + str(tlagq99))\n",
    "del_TLAG99 = crsp_comp_edgar.loc[crsp_comp_edgar['TLAG'] > tlagq99].shape[0]\n",
    "print('number of obs. that contain negative or larger than 99% TLAG: ' + str(del_TLAG99 + del_TLAG0))\n",
    "crsp_comp_edgar = crsp_comp_edgar.loc[crsp_comp_edgar['TLAG'] <= tlagq99]\n",
    "\n",
    "############## Inspect sample size after variable screening\n",
    "print('Number of obs. after variable screening: ' + str(crsp_comp_edgar.shape[0]))\n",
    "\n",
    "############## Winsorize SIZE, MTB, LEV\n",
    "###### Define a function that winsorize a variable at 1% and 99% \n",
    "def winsorize (df, colnames):\n",
    "    for col in colnames:\n",
    "        varq01 = df[col].quantile(.01)\n",
    "        varq99 = df[col].quantile(.99)\n",
    "        df[col] = df[col].clip(varq01, varq99)\n",
    "    return df\n",
    "\n",
    "crsp_comp_edgar = winsorize(crsp_comp_edgar, ['SIZE', 'MTB', 'LEV', 'EARN', 'DEARN', 'STD_EARN', 'STD_RET'])\n",
    "\n",
    "############## Save processed CRSP_COMP_EDGAR to .csv file\n",
    "crsp_comp_edgar.to_csv('..\\\\filings\\\\crsp_comp_edgar_'+ obj_type + '.csv', index = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>NW</td>\n",
       "      <td>244401.0</td>\n",
       "      <td>6.086185</td>\n",
       "      <td>0.898564</td>\n",
       "      <td>4.897840</td>\n",
       "      <td>5.560682</td>\n",
       "      <td>5.849325</td>\n",
       "      <td>6.350886</td>\n",
       "      <td>13.579750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>nw</td>\n",
       "      <td>244401.0</td>\n",
       "      <td>1257.747599</td>\n",
       "      <td>6278.552634</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>259.000000</td>\n",
       "      <td>346.000000</td>\n",
       "      <td>572.000000</td>\n",
       "      <td>789969.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TONE</td>\n",
       "      <td>244401.0</td>\n",
       "      <td>-0.450802</td>\n",
       "      <td>7.322881</td>\n",
       "      <td>-97.850863</td>\n",
       "      <td>-2.865330</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.676471</td>\n",
       "      <td>50.898204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TLAG</td>\n",
       "      <td>244401.0</td>\n",
       "      <td>22.668622</td>\n",
       "      <td>25.018335</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>142.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RET</td>\n",
       "      <td>244401.0</td>\n",
       "      <td>0.002671</td>\n",
       "      <td>0.093588</td>\n",
       "      <td>-0.952027</td>\n",
       "      <td>-0.038285</td>\n",
       "      <td>-0.003215</td>\n",
       "      <td>0.040603</td>\n",
       "      <td>6.605908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DRET</td>\n",
       "      <td>244401.0</td>\n",
       "      <td>-0.014977</td>\n",
       "      <td>0.173880</td>\n",
       "      <td>-9.062400</td>\n",
       "      <td>-0.114382</td>\n",
       "      <td>-0.046758</td>\n",
       "      <td>0.096238</td>\n",
       "      <td>6.597161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>BN</td>\n",
       "      <td>244401.0</td>\n",
       "      <td>0.537473</td>\n",
       "      <td>0.498595</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>SIZE</td>\n",
       "      <td>244401.0</td>\n",
       "      <td>6.394941</td>\n",
       "      <td>1.974545</td>\n",
       "      <td>2.173899</td>\n",
       "      <td>5.003671</td>\n",
       "      <td>6.337343</td>\n",
       "      <td>7.712362</td>\n",
       "      <td>11.409459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>MTB</td>\n",
       "      <td>244401.0</td>\n",
       "      <td>3.798193</td>\n",
       "      <td>4.829783</td>\n",
       "      <td>0.161413</td>\n",
       "      <td>1.394139</td>\n",
       "      <td>2.338994</td>\n",
       "      <td>4.124108</td>\n",
       "      <td>33.727315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LEV</td>\n",
       "      <td>244401.0</td>\n",
       "      <td>0.204996</td>\n",
       "      <td>0.193290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011789</td>\n",
       "      <td>0.172230</td>\n",
       "      <td>0.334465</td>\n",
       "      <td>0.748998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>EARN</td>\n",
       "      <td>244347.0</td>\n",
       "      <td>-0.011030</td>\n",
       "      <td>0.068999</td>\n",
       "      <td>-0.350865</td>\n",
       "      <td>-0.013308</td>\n",
       "      <td>0.007751</td>\n",
       "      <td>0.020161</td>\n",
       "      <td>0.110306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DEARN</td>\n",
       "      <td>244265.0</td>\n",
       "      <td>-0.000450</td>\n",
       "      <td>0.052078</td>\n",
       "      <td>-0.228392</td>\n",
       "      <td>-0.009509</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.008251</td>\n",
       "      <td>0.251171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>STD_EARN</td>\n",
       "      <td>243071.0</td>\n",
       "      <td>0.028294</td>\n",
       "      <td>0.046743</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>0.005496</td>\n",
       "      <td>0.011958</td>\n",
       "      <td>0.028872</td>\n",
       "      <td>0.309783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>STD_RET</td>\n",
       "      <td>244401.0</td>\n",
       "      <td>0.032508</td>\n",
       "      <td>0.020090</td>\n",
       "      <td>0.008479</td>\n",
       "      <td>0.018589</td>\n",
       "      <td>0.027064</td>\n",
       "      <td>0.040379</td>\n",
       "      <td>0.115942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LOSS</td>\n",
       "      <td>244401.0</td>\n",
       "      <td>0.350854</td>\n",
       "      <td>0.477238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count         mean          std         min         25%  \\\n",
       "NW        244401.0     6.086185     0.898564    4.897840    5.560682   \n",
       "nw        244401.0  1257.747599  6278.552634  133.000000  259.000000   \n",
       "TONE      244401.0    -0.450802     7.322881  -97.850863   -2.865330   \n",
       "TLAG      244401.0    22.668622    25.018335    0.000000    4.000000   \n",
       "RET       244401.0     0.002671     0.093588   -0.952027   -0.038285   \n",
       "DRET      244401.0    -0.014977     0.173880   -9.062400   -0.114382   \n",
       "BN        244401.0     0.537473     0.498595    0.000000    0.000000   \n",
       "SIZE      244401.0     6.394941     1.974545    2.173899    5.003671   \n",
       "MTB       244401.0     3.798193     4.829783    0.161413    1.394139   \n",
       "LEV       244401.0     0.204996     0.193290    0.000000    0.011789   \n",
       "EARN      244347.0    -0.011030     0.068999   -0.350865   -0.013308   \n",
       "DEARN     244265.0    -0.000450     0.052078   -0.228392   -0.009509   \n",
       "STD_EARN  243071.0     0.028294     0.046743    0.001062    0.005496   \n",
       "STD_RET   244401.0     0.032508     0.020090    0.008479    0.018589   \n",
       "LOSS      244401.0     0.350854     0.477238    0.000000    0.000000   \n",
       "\n",
       "                 50%         75%            max  \n",
       "NW          5.849325    6.350886      13.579750  \n",
       "nw        346.000000  572.000000  789969.000000  \n",
       "TONE        0.000000    3.676471      50.898204  \n",
       "TLAG       14.000000   33.000000     142.000000  \n",
       "RET        -0.003215    0.040603       6.605908  \n",
       "DRET       -0.046758    0.096238       6.597161  \n",
       "BN          1.000000    1.000000       1.000000  \n",
       "SIZE        6.337343    7.712362      11.409459  \n",
       "MTB         2.338994    4.124108      33.727315  \n",
       "LEV         0.172230    0.334465       0.748998  \n",
       "EARN        0.007751    0.020161       0.110306  \n",
       "DEARN       0.000071    0.008251       0.251171  \n",
       "STD_EARN    0.011958    0.028872       0.309783  \n",
       "STD_RET     0.027064    0.040379       0.115942  \n",
       "LOSS        0.000000    1.000000       1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########################################################################################\n",
    "############### Table 1: Summary Statistics and Correlation Matrix #####################\n",
    "########################################################################################\n",
    "\n",
    "############# Table 1 Panel A: Summary statistics for selected variables\n",
    "######### Variable groups:\n",
    "# 1st line: textual variables, generally consistent with LM's summary statistics\n",
    "# 2nd line: fundamental variables (main)\n",
    "# 3rd line: abtone\n",
    "selected_vars = crsp_comp_edgar[['NW','nw', 'TONE','TLAG', \\\n",
    "                                 'RET', 'DRET', 'BN', 'SIZE', 'MTB', 'LEV', \\\n",
    "                                 'EARN', 'DEARN', 'STD_EARN', 'STD_RET', 'LOSS']]\n",
    "\n",
    "T7PA = selected_vars.describe().transpose() \n",
    "\n",
    "############# Summary statistics for all raw and processed variables\n",
    "full_summary = crsp_comp_edgar.describe().transpose()\n",
    "\n",
    "############# Save T1PA\n",
    "table_path = '..\\\\output\\\\Tables.xlsx'\n",
    "if os.path.exists(table_path) == True:\n",
    "    book = load_workbook(table_path)\n",
    "    writer = pd.ExcelWriter(table_path, engine = 'openpyxl')\n",
    "    writer.book = book\n",
    "    writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "\n",
    "    T7PA.to_excel(writer, sheet_name='T7PA_raw', float_format=\"%.4f\")\n",
    "\n",
    "    writer.save()\n",
    "    writer.close()\n",
    "    \n",
    "else:\n",
    "    T7PA.to_excel(table_path, sheet_name='T7PA_raw', float_format=\"%.4f\")\n",
    "\n",
    "T7PA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Table 1 Panel B: Correlation matrix for selected variables\n",
    "######### pearson correlation\n",
    "T7PB_pearson = selected_vars.corr(method='pearson')\n",
    "\n",
    "# T1PB_pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### spearman correlation\n",
    "T7PB_spearman = selected_vars.corr(method='spearman')\n",
    "\n",
    "# T1PB_spearman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NW</th>\n",
       "      <th>nw</th>\n",
       "      <th>TONE</th>\n",
       "      <th>TLAG</th>\n",
       "      <th>RET</th>\n",
       "      <th>DRET</th>\n",
       "      <th>BN</th>\n",
       "      <th>SIZE</th>\n",
       "      <th>MTB</th>\n",
       "      <th>LEV</th>\n",
       "      <th>EARN</th>\n",
       "      <th>DEARN</th>\n",
       "      <th>STD_EARN</th>\n",
       "      <th>STD_RET</th>\n",
       "      <th>LOSS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>NW</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.643744</td>\n",
       "      <td>-0.425374</td>\n",
       "      <td>0.118591</td>\n",
       "      <td>0.017970</td>\n",
       "      <td>-0.014366</td>\n",
       "      <td>0.011237</td>\n",
       "      <td>-0.022363</td>\n",
       "      <td>0.036647</td>\n",
       "      <td>0.076249</td>\n",
       "      <td>-0.048435</td>\n",
       "      <td>-0.017068</td>\n",
       "      <td>0.048922</td>\n",
       "      <td>0.093056</td>\n",
       "      <td>0.038183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>nw</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.230981</td>\n",
       "      <td>0.101280</td>\n",
       "      <td>0.014255</td>\n",
       "      <td>-0.008306</td>\n",
       "      <td>0.007389</td>\n",
       "      <td>-0.047188</td>\n",
       "      <td>0.016673</td>\n",
       "      <td>0.041908</td>\n",
       "      <td>-0.016377</td>\n",
       "      <td>-0.012377</td>\n",
       "      <td>0.021884</td>\n",
       "      <td>0.066712</td>\n",
       "      <td>0.008589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TONE</td>\n",
       "      <td>-0.418633</td>\n",
       "      <td>-0.418633</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.061180</td>\n",
       "      <td>0.002318</td>\n",
       "      <td>0.015711</td>\n",
       "      <td>-0.010027</td>\n",
       "      <td>0.069758</td>\n",
       "      <td>0.007355</td>\n",
       "      <td>-0.034188</td>\n",
       "      <td>0.040844</td>\n",
       "      <td>0.003128</td>\n",
       "      <td>-0.043816</td>\n",
       "      <td>-0.104180</td>\n",
       "      <td>-0.053295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TLAG</td>\n",
       "      <td>0.082457</td>\n",
       "      <td>0.082457</td>\n",
       "      <td>-0.078595</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.014068</td>\n",
       "      <td>-0.034163</td>\n",
       "      <td>0.032670</td>\n",
       "      <td>-0.093047</td>\n",
       "      <td>-0.003669</td>\n",
       "      <td>-0.045075</td>\n",
       "      <td>0.027635</td>\n",
       "      <td>0.001286</td>\n",
       "      <td>-0.012639</td>\n",
       "      <td>0.005035</td>\n",
       "      <td>-0.019684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RET</td>\n",
       "      <td>-0.000187</td>\n",
       "      <td>-0.000187</td>\n",
       "      <td>0.007532</td>\n",
       "      <td>-0.014378</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.732346</td>\n",
       "      <td>-0.574272</td>\n",
       "      <td>-0.022847</td>\n",
       "      <td>0.007161</td>\n",
       "      <td>0.002933</td>\n",
       "      <td>0.004111</td>\n",
       "      <td>-0.004440</td>\n",
       "      <td>0.011739</td>\n",
       "      <td>0.039335</td>\n",
       "      <td>-0.010578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DRET</td>\n",
       "      <td>-0.012012</td>\n",
       "      <td>-0.012012</td>\n",
       "      <td>0.017983</td>\n",
       "      <td>-0.041143</td>\n",
       "      <td>0.794933</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.753039</td>\n",
       "      <td>0.064169</td>\n",
       "      <td>-0.001143</td>\n",
       "      <td>0.012250</td>\n",
       "      <td>0.057691</td>\n",
       "      <td>-0.000878</td>\n",
       "      <td>-0.050642</td>\n",
       "      <td>-0.109435</td>\n",
       "      <td>-0.048053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>BN</td>\n",
       "      <td>0.009003</td>\n",
       "      <td>0.009003</td>\n",
       "      <td>-0.010745</td>\n",
       "      <td>0.041733</td>\n",
       "      <td>-0.792314</td>\n",
       "      <td>-0.863590</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.029447</td>\n",
       "      <td>-0.001193</td>\n",
       "      <td>-0.008487</td>\n",
       "      <td>-0.024931</td>\n",
       "      <td>0.002675</td>\n",
       "      <td>0.020692</td>\n",
       "      <td>0.036860</td>\n",
       "      <td>0.023475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>SIZE</td>\n",
       "      <td>0.030474</td>\n",
       "      <td>0.030474</td>\n",
       "      <td>0.074186</td>\n",
       "      <td>-0.102757</td>\n",
       "      <td>0.022006</td>\n",
       "      <td>0.073140</td>\n",
       "      <td>-0.029317</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.195302</td>\n",
       "      <td>0.172287</td>\n",
       "      <td>0.305099</td>\n",
       "      <td>0.002835</td>\n",
       "      <td>-0.255154</td>\n",
       "      <td>-0.559434</td>\n",
       "      <td>-0.323926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>MTB</td>\n",
       "      <td>0.042608</td>\n",
       "      <td>0.042608</td>\n",
       "      <td>0.030240</td>\n",
       "      <td>-0.010863</td>\n",
       "      <td>0.008137</td>\n",
       "      <td>0.014284</td>\n",
       "      <td>-0.007078</td>\n",
       "      <td>0.351901</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.095941</td>\n",
       "      <td>-0.094352</td>\n",
       "      <td>0.038886</td>\n",
       "      <td>0.149502</td>\n",
       "      <td>0.008121</td>\n",
       "      <td>0.028244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LEV</td>\n",
       "      <td>0.082614</td>\n",
       "      <td>0.082614</td>\n",
       "      <td>-0.043243</td>\n",
       "      <td>-0.054919</td>\n",
       "      <td>0.012086</td>\n",
       "      <td>0.021003</td>\n",
       "      <td>-0.011102</td>\n",
       "      <td>0.218020</td>\n",
       "      <td>-0.033093</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.080124</td>\n",
       "      <td>0.029841</td>\n",
       "      <td>-0.124194</td>\n",
       "      <td>-0.080442</td>\n",
       "      <td>-0.048491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>EARN</td>\n",
       "      <td>-0.059431</td>\n",
       "      <td>-0.059431</td>\n",
       "      <td>0.068576</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.043084</td>\n",
       "      <td>0.054910</td>\n",
       "      <td>-0.023332</td>\n",
       "      <td>0.355008</td>\n",
       "      <td>0.182249</td>\n",
       "      <td>-0.000375</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.371458</td>\n",
       "      <td>-0.474179</td>\n",
       "      <td>-0.432680</td>\n",
       "      <td>-0.612458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>DEARN</td>\n",
       "      <td>-0.012847</td>\n",
       "      <td>-0.012847</td>\n",
       "      <td>-0.000434</td>\n",
       "      <td>0.011143</td>\n",
       "      <td>-0.001133</td>\n",
       "      <td>-0.001644</td>\n",
       "      <td>0.004048</td>\n",
       "      <td>0.008344</td>\n",
       "      <td>0.034422</td>\n",
       "      <td>0.016781</td>\n",
       "      <td>0.349332</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.019926</td>\n",
       "      <td>-0.017160</td>\n",
       "      <td>-0.193048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>STD_EARN</td>\n",
       "      <td>0.051070</td>\n",
       "      <td>0.051070</td>\n",
       "      <td>-0.060046</td>\n",
       "      <td>0.004223</td>\n",
       "      <td>-0.027452</td>\n",
       "      <td>-0.056193</td>\n",
       "      <td>0.021464</td>\n",
       "      <td>-0.362558</td>\n",
       "      <td>0.062628</td>\n",
       "      <td>-0.195119</td>\n",
       "      <td>-0.369986</td>\n",
       "      <td>-0.030619</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.381915</td>\n",
       "      <td>0.319078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>STD_RET</td>\n",
       "      <td>0.038009</td>\n",
       "      <td>0.038009</td>\n",
       "      <td>-0.111369</td>\n",
       "      <td>0.027252</td>\n",
       "      <td>-0.033826</td>\n",
       "      <td>-0.097333</td>\n",
       "      <td>0.033908</td>\n",
       "      <td>-0.638367</td>\n",
       "      <td>-0.142410</td>\n",
       "      <td>-0.156546</td>\n",
       "      <td>-0.427688</td>\n",
       "      <td>-0.026799</td>\n",
       "      <td>0.493386</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.402552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LOSS</td>\n",
       "      <td>0.051573</td>\n",
       "      <td>0.051573</td>\n",
       "      <td>-0.062324</td>\n",
       "      <td>-0.002270</td>\n",
       "      <td>-0.039863</td>\n",
       "      <td>-0.054205</td>\n",
       "      <td>0.023475</td>\n",
       "      <td>-0.332569</td>\n",
       "      <td>-0.079470</td>\n",
       "      <td>-0.076070</td>\n",
       "      <td>-0.815824</td>\n",
       "      <td>-0.272878</td>\n",
       "      <td>0.456275</td>\n",
       "      <td>0.432987</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                NW        nw      TONE      TLAG       RET      DRET  \\\n",
       "NW        1.000000  0.643744 -0.425374  0.118591  0.017970 -0.014366   \n",
       "nw        1.000000  1.000000 -0.230981  0.101280  0.014255 -0.008306   \n",
       "TONE     -0.418633 -0.418633  1.000000 -0.061180  0.002318  0.015711   \n",
       "TLAG      0.082457  0.082457 -0.078595  1.000000 -0.014068 -0.034163   \n",
       "RET      -0.000187 -0.000187  0.007532 -0.014378  1.000000  0.732346   \n",
       "DRET     -0.012012 -0.012012  0.017983 -0.041143  0.794933  1.000000   \n",
       "BN        0.009003  0.009003 -0.010745  0.041733 -0.792314 -0.863590   \n",
       "SIZE      0.030474  0.030474  0.074186 -0.102757  0.022006  0.073140   \n",
       "MTB       0.042608  0.042608  0.030240 -0.010863  0.008137  0.014284   \n",
       "LEV       0.082614  0.082614 -0.043243 -0.054919  0.012086  0.021003   \n",
       "EARN     -0.059431 -0.059431  0.068576  0.005556  0.043084  0.054910   \n",
       "DEARN    -0.012847 -0.012847 -0.000434  0.011143 -0.001133 -0.001644   \n",
       "STD_EARN  0.051070  0.051070 -0.060046  0.004223 -0.027452 -0.056193   \n",
       "STD_RET   0.038009  0.038009 -0.111369  0.027252 -0.033826 -0.097333   \n",
       "LOSS      0.051573  0.051573 -0.062324 -0.002270 -0.039863 -0.054205   \n",
       "\n",
       "                BN      SIZE       MTB       LEV      EARN     DEARN  \\\n",
       "NW        0.011237 -0.022363  0.036647  0.076249 -0.048435 -0.017068   \n",
       "nw        0.007389 -0.047188  0.016673  0.041908 -0.016377 -0.012377   \n",
       "TONE     -0.010027  0.069758  0.007355 -0.034188  0.040844  0.003128   \n",
       "TLAG      0.032670 -0.093047 -0.003669 -0.045075  0.027635  0.001286   \n",
       "RET      -0.574272 -0.022847  0.007161  0.002933  0.004111 -0.004440   \n",
       "DRET     -0.753039  0.064169 -0.001143  0.012250  0.057691 -0.000878   \n",
       "BN        1.000000 -0.029447 -0.001193 -0.008487 -0.024931  0.002675   \n",
       "SIZE     -0.029317  1.000000  0.195302  0.172287  0.305099  0.002835   \n",
       "MTB      -0.007078  0.351901  1.000000  0.095941 -0.094352  0.038886   \n",
       "LEV      -0.011102  0.218020 -0.033093  1.000000  0.080124  0.029841   \n",
       "EARN     -0.023332  0.355008  0.182249 -0.000375  1.000000  0.371458   \n",
       "DEARN     0.004048  0.008344  0.034422  0.016781  0.349332  1.000000   \n",
       "STD_EARN  0.021464 -0.362558  0.062628 -0.195119 -0.369986 -0.030619   \n",
       "STD_RET   0.033908 -0.638367 -0.142410 -0.156546 -0.427688 -0.026799   \n",
       "LOSS      0.023475 -0.332569 -0.079470 -0.076070 -0.815824 -0.272878   \n",
       "\n",
       "          STD_EARN   STD_RET      LOSS  \n",
       "NW        0.048922  0.093056  0.038183  \n",
       "nw        0.021884  0.066712  0.008589  \n",
       "TONE     -0.043816 -0.104180 -0.053295  \n",
       "TLAG     -0.012639  0.005035 -0.019684  \n",
       "RET       0.011739  0.039335 -0.010578  \n",
       "DRET     -0.050642 -0.109435 -0.048053  \n",
       "BN        0.020692  0.036860  0.023475  \n",
       "SIZE     -0.255154 -0.559434 -0.323926  \n",
       "MTB       0.149502  0.008121  0.028244  \n",
       "LEV      -0.124194 -0.080442 -0.048491  \n",
       "EARN     -0.474179 -0.432680 -0.612458  \n",
       "DEARN    -0.019926 -0.017160 -0.193048  \n",
       "STD_EARN  1.000000  0.381915  0.319078  \n",
       "STD_RET   0.493386  1.000000  0.402552  \n",
       "LOSS      0.456275  0.432987  1.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######### Combine two correlation matrices. right-up matrix: pearson; left-down matrix: spearman \n",
    "for row in list(range(0, len(T7PB_spearman.index))):\n",
    "    T7PB_spearman.iloc[row, row+1:] = T7PB_pearson.iloc[row, row+1:]\n",
    "    \n",
    "##### Save T1PB\n",
    "table_path = '..\\\\output\\\\Tables.xlsx'\n",
    "if os.path.exists(table_path) == True:\n",
    "    book = load_workbook(table_path)\n",
    "    writer = pd.ExcelWriter(table_path, engine = 'openpyxl')\n",
    "    writer.book = book\n",
    "    writer.sheets = dict((ws.title, ws) for ws in book.worksheets)\n",
    "\n",
    "    T7PB_spearman.to_excel(writer, sheet_name='T7PB_raw', float_format=\"%.4f\")\n",
    "\n",
    "    writer.save()\n",
    "    writer.close()\n",
    "    \n",
    "else:\n",
    "    T7PB_spearman.to_excel(table_path, sheet_name='T7PB_raw', float_format=\"%.4f\")\n",
    "\n",
    "T7PB_spearman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Import packages\n",
    "import os, numpy as np, pandas as pd, time, glob, re, math, statsmodels.api as sm, patsy as ps, matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from time import process_time\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "from openpyxl import load_workbook\n",
    "from patsy import dmatrices\n",
    "from matplotlib import rc\n",
    "\n",
    "##########################################################\n",
    "##################### parameter ##########################\n",
    "##########################################################\n",
    "obj_type = '8-K'\n",
    "data_type_text = 'text_data'\n",
    "data_type_id = 'id_data'\n",
    "\n",
    "############### Set working directory to parent directory\n",
    "if os.getcwd() != 'F:\\\\github\\\\narrative_conservatism\\\\code':\n",
    "    os.chdir('F:\\\\github\\\\narrative_conservatism\\\\code')\n",
    "    \n",
    "############### Set pandas column printing constraint\n",
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-26765d41d4b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m                   'atq', 'lag_atq', 'ceqq', 'lag_ceqq', 'lag_cshoq', 'lag_dlcq', 'lag_dlttq', 'lag_prccq']\n\u001b[0;32m      8\u001b[0m crsp_comp = pd.read_csv(r'H:\\data\\github_big_files\\crsp_comp_' + obj_type + '.csv', \\\n\u001b[1;32m----> 9\u001b[1;33m                         usecols = crsp_comp_cols, dtype = {'cik': str, 'cusip': str, 'date_key': str})\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m### Delete last two digits (.0) of crsp_comp['cik']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\python\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\python\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 463\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    464\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\python\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1152\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1154\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\python\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2057\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2058\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2059\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2060\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2061\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mE:\\python\\lib\\site-packages\\pandas\\core\\dtypes\\common.py\u001b[0m in \u001b[0;36mis_categorical_dtype\u001b[1;34m(arr_or_dtype)\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m     \"\"\"\n\u001b[0;32m    680\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0man\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlike\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mCategorical\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "########################################################################################\n",
    "################## Merge EDGAR with CRSP_COMPUSTAT: RETURN #############################\n",
    "########################################################################################\n",
    "\n",
    "########## Load CRSP_COMP dataset\n",
    "crsp_comp_cols = ['date_crsp', 'cusip', 'cik', 'RET', 'DRET', 'date_key', 'fyearq', 'sic', 'BN', 'NEWS', \\\n",
    "                  'atq', 'lag_atq', 'ceqq', 'lag_ceqq', 'lag_cshoq', 'lag_dlcq', 'lag_dlttq', 'lag_prccq']\n",
    "crsp_comp = pd.read_csv(r'H:\\data\\github_big_files\\crsp_comp_' + obj_type + '.csv', \\\n",
    "                        usecols = crsp_comp_cols, dtype = {'cik': str, 'cusip': str, 'date_key': str})\n",
    "\n",
    "### Delete last two digits (.0) of crsp_comp['cik'] \n",
    "crsp_comp['cik'] = crsp_comp['cik'].astype(str).str[:-2]\n",
    "\n",
    "### Sort CRSP_COMP by cik-date_key in order to match NEWS and EDGAR later\n",
    "crsp_comp = crsp_comp.sort_values(by = ['cik', 'date_key'])\n",
    "crsp_comp['date_key'] = pd.to_datetime(crsp_comp['date_key'], format='%Y%m%d')\n",
    "\n",
    "########## Load EDGAR dataset\n",
    "edgar_cols = ['cik', 'rp', 'fd', 'item8k', 'name', 'n8k', 'nw', 'nvocab', 'n_neg', 'n_pos', 'n_negation', 'tone']\n",
    "edgar = pd.read_csv('..\\\\filings\\\\edgar_8-K.csv', usecols = edgar_cols, dtype = {'cik': str, 'date_key': str})\n",
    "\n",
    "### Sort CRSP_COMP by cik-date_key in order to match NEWS and EDGAR later\n",
    "edgar['date_key'] = edgar['fd']\n",
    "edgar['date_key'] = pd.to_datetime(edgar['date_key'], format='%Y%m%d')\n",
    "edgar = edgar.sort_values(by = ['cik', 'date_key'])\n",
    "\n",
    "############## Left merge CRSP_COMP and EDGAR, key unique in both data sets\n",
    "crsp_comp_edgar = pd.merge(crsp_comp, edgar, on = ['cik', 'date_key'], how = 'left', validate = '1:m')\n",
    "\n",
    "del edgar, crsp_comp\n",
    "\n",
    "############# restrict samples to good and bad news as defined as\n",
    "# Firm-day's positive (negative) RET change is three times larger than the firm’s calander yearly average increase (decrease) in RET, \n",
    "# and 0 otherwise.\n",
    "crsp_comp_edgar = crsp_comp_edgar[crsp_comp_edgar['NEWS']==1]\n",
    "crsp_comp_edgar = crsp_comp_edgar.drop(['NEWS'], axis = 1) \n",
    "\n",
    "# ############# generate CR and NEG\n",
    "# crsp_comp_edgar['lag1_RET'] = crsp_comp_edgar.groupby(['cik'])['RET'].shift(1)\n",
    "# crsp_comp_edgar['leap1_RET'] = crsp_comp_edgar.groupby(['cik'])['RET'].shift(-1)\n",
    "# crsp_comp_edgar['CR3'] = crsp_comp_edgar['RET'] + crsp_comp_edgar['leap1_RET'] + crsp_comp_edgar['lag1_RET']\n",
    "# crsp_comp_edgar.drop(['lag1_RET', 'leap1_RET'], axis=1)\n",
    "\n",
    "# ############# restrict samples to good and bad news as defined as\n",
    "# # (a)\n",
    "# # 3-day cummulative return is three times larger than the firm’s calander yearly average increase (decrease) in RET\n",
    "# crsp_comp_edgar['NEG3'] = 0\n",
    "# crsp_comp_edgar.loc[crsp_comp_edgar['CR3']<0, 'NEG3'] = 1\n",
    "\n",
    "# crsp_comp_edgar['lag2_RET'] = crsp_comp_edgar.groupby(['cik'])['RET'].shift(2)\n",
    "# crsp_comp_edgar['leap2_RET'] = crsp_comp_edgar.groupby(['cik'])['RET'].shift(-2)\n",
    "# crsp_comp_edgar['CR5'] = crsp_comp_edgar['CR3'] + crsp_comp_edgar['leap2_RET'] + crsp_comp_edgar['lag2_RET']\n",
    "# crsp_comp_edgar.drop(['lag2_RET', 'leap2_RET'], axis=1)\n",
    "\n",
    "# crsp_comp_edgar['NEG5'] = 0\n",
    "# crsp_comp_edgar.loc[crsp_comp_edgar['CR5']<0, 'NEG3'] = 1\n",
    "\n",
    "# crsp_comp_edgar['lag3_RET'] = crsp_comp_edgar.groupby(['cik'])['RET'].shift(3)\n",
    "# crsp_comp_edgar['leap3_RET'] = crsp_comp_edgar.groupby(['cik'])['RET'].shift(-3)\n",
    "# crsp_comp_edgar['CR7'] = crsp_comp_edgar['CR5'] + crsp_comp_edgar['leap3_RET'] + crsp_comp_edgar['lag3_RET']\n",
    "# crsp_comp_edgar.drop(['lag3_RET', 'leap3_RET'], axis=1)\n",
    "\n",
    "# crsp_comp_edgar['NEG7'] = 0\n",
    "# crsp_comp_edgar.loc[crsp_comp_edgar['CR7']<0, 'NEG3'] = 1\n",
    "\n",
    "############ delete other firm-days without 8-K\n",
    "crsp_comp_edgar = crsp_comp_edgar[crsp_comp_edgar['rp'].notnull()]\n",
    "\n",
    "############## Rename SIC\n",
    "crsp_comp_edgar = crsp_comp_edgar.rename(columns={'sic': 'SIC'})\n",
    "\n",
    "############### Create item_8k count variable set and Load processed EDGAR_8-K\n",
    "\n",
    "item_before2004 = ['1','2','3','4','5','6','7','8','9','10','11','12']\n",
    "item_before2004 = ['item_' + item for item in item_before2004]\n",
    "item_after2004 = ['1.01','1.02','1.03','1.04', \\\n",
    "                  '2.01','2.02','2.03','2.04','2.05','2.06', \\\n",
    "                  '3.01','3.02','3.03', \\\n",
    "                  '4.01','4.02',\n",
    "                  '5.01','5.02','5.03','5.04','5.05','5.06','5.07','5.08', \\\n",
    "                  '6.01','6.02','6.03','6.04','6.05', \\\n",
    "                  '7.01', \\\n",
    "                  '8.01', \\\n",
    "                  '9.01']\n",
    "item_after2004 = ['item_' + item for item in item_after2004]\n",
    "item  = item_before2004 + item_after2004\n",
    "\n",
    "edgar_cols = ['cik', 'rp'] + item\n",
    "edgar = pd.read_csv(r'..\\filings\\edgar_' + obj_type + '.csv', usecols = edgar_cols, dtype={'cik': str})\n",
    "\n",
    "############## Add financial variables from CRSP_COMP to CRSP_COMP_EDGAR by merging\n",
    "crsp_comp_edgar = pd.merge(crsp_comp_edgar, edgar, on = ['cik', 'rp'], how = 'left', validate = '1:1')\n",
    "del edgar\n",
    "\n",
    "############## Create filing date year-month fixed effects identifier cmonth\n",
    "crsp_comp_edgar['cmonth'] = crsp_comp_edgar['fd'].astype(str).str[:-2]\n",
    "\n",
    "############## Create nitem as count of total number of items appeared in one firm-day\n",
    "crsp_comp_edgar['nitem'] = crsp_comp_edgar.loc[:,item].sum(axis = 1)\n",
    "\n",
    "############# Reorder crsp_comp_edgar columns\n",
    "# 1st line: merge keys\n",
    "# 2nd line: extra id info\n",
    "# 3th line: financial raw data (lagged variables)\n",
    "# 4th line: text variables\n",
    "crsp_comp_edgar = crsp_comp_edgar[['cusip', 'date_crsp', 'cik', 'rp', \\\n",
    "                                   'name', 'SIC', 'fd', 'cmonth', 'fyearq', \\\n",
    "                                   'atq', 'lag_atq', 'ceqq', 'lag_ceqq', 'lag_cshoq', 'lag_dlcq', 'lag_dlttq', 'lag_prccq', 'RET', 'NEG', 'DRET', 'BN', \\\n",
    "                                   'n8k', 'nitem', 'nw', 'nvocab', 'n_neg', 'n_pos', 'n_negation', 'tone'] + item]\n",
    "\n",
    "print('Number of obs. in CRSP_COMP_EDGAR: ' + str(crsp_comp_edgar.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\python\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "E:\\python\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "E:\\python\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "E:\\python\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of obs. with missing SIC: 3409\n"
     ]
    }
   ],
   "source": [
    "####################### Modify data type in ID_CRSP_COMP_TEXT\n",
    "########### Define a function that changes pandas series data type to string\n",
    "def columns_to_str (df, colnames):\n",
    "    for col in colnames:\n",
    "        df[col] = df[col].astype(str)\n",
    "    return df\n",
    "\n",
    "########### Apply columns_to_str to various identification variables\n",
    "crsp_comp_edgar = columns_to_str(crsp_comp_edgar, ['cik', 'cusip', 'fyearq'])\n",
    "\n",
    "########## Convert date variables to date format\n",
    "crsp_comp_edgar['date_crsp'] = pd.to_datetime(crsp_comp_edgar['date_crsp'], format='%Y%m%d')\n",
    "crsp_comp_edgar['fd'] = pd.to_datetime(crsp_comp_edgar['fd'], format='%Y%m%d')\n",
    "crsp_comp_edgar['rp'] = pd.to_datetime(crsp_comp_edgar['rp'], format='%Y%m%d')\n",
    "\n",
    "############## Drop obs. with missing SIC and convert SIC variables to integer\n",
    "del_sic = crsp_comp_edgar[crsp_comp_edgar['SIC'].isnull()].shape[0]\n",
    "crsp_comp_edgar = crsp_comp_edgar[crsp_comp_edgar['SIC'].notnull()]\n",
    "print('Number of obs. with missing SIC: ' + str(del_sic))\n",
    "\n",
    "crsp_comp_edgar['SIC'] = crsp_comp_edgar['SIC'].astype(int)\n",
    "\n",
    "########### Inspect column data types\n",
    "# print(crsp_comp_edgar.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of obs. with beginning common share price less than $1: 2427\n",
      "Number of obs. with non-positive common shares outstanding: 15\n"
     ]
    }
   ],
   "source": [
    "########################################################################################\n",
    "############################### Variable Creation ######################################\n",
    "########################################################################################\n",
    "\n",
    "############################## Main Variables ##########################################\n",
    "######## NW: natural log of 1 + total number of words in the document\n",
    "crsp_comp_edgar['NW'] = np.log(1 + crsp_comp_edgar['nw'])\n",
    "\n",
    "######## TONE: number of net positive words (n_pos - n_neg - n_negations) per 1000 total words\n",
    "crsp_comp_edgar['TONE'] = crsp_comp_edgar['tone']*1000\n",
    "\n",
    "######## TLAG: Time lag between the news release date (CRSP date) and document filing date (EDGAR filing date)\n",
    "crsp_comp_edgar['TLAG'] = (crsp_comp_edgar['fd'] - crsp_comp_edgar['rp']).dt.days\n",
    "\n",
    "### BN: An indicator of bad news, which takes 1 in a firm-day when the firm-day's negative RET change \\\n",
    "### is three times larger than the firm’s current calander-yearly average decrease in RET, and 0 if there is good news.\n",
    "\n",
    "############## Drop obs. with [beginning-of-quarter] common share price less than $1\n",
    "del_prccq = crsp_comp_edgar.loc[(crsp_comp_edgar['lag_prccq'] < 1) | (crsp_comp_edgar['lag_prccq'].isnull())].shape[0]\n",
    "crsp_comp_edgar = crsp_comp_edgar.loc[crsp_comp_edgar['lag_prccq'] >= 1]\n",
    "print('Number of obs. with beginning common share price less than $1: ' + str(del_prccq))\n",
    "\n",
    "############## Drop obs. with [beginning-of-quarter] non-positive common shares outstanding\n",
    "del_cshoq = crsp_comp_edgar.loc[(crsp_comp_edgar['lag_cshoq'] == 0) | (crsp_comp_edgar['lag_cshoq'].isnull())].shape[0]\n",
    "crsp_comp_edgar = crsp_comp_edgar.loc[crsp_comp_edgar['lag_cshoq'] > 0]\n",
    "print('Number of obs. with non-positive common shares outstanding: ' + str(del_cshoq))\n",
    "\n",
    "############################## Control Variables #######################################\n",
    "######## Size: Firm size, defined as the natural logarithm of market value of equity [at the beginning of the quarter] \\\n",
    "######## defined as [beginning-of-quarter] common share price (Compustat data item prccq) \\\n",
    "######## times [beginning-of-quarter] common shares outstanding (Compustat data item cshoq)\n",
    "crsp_comp_edgar['SIZE'] = np.log(crsp_comp_edgar['lag_prccq']*crsp_comp_edgar['lag_cshoq'])\n",
    "\n",
    "######## MTB: Market-to-book ratio, defined as [beginning-of-quarter] market value of equity \\\n",
    "######## defined as common share price (Compustat data item prccq) times common shares outstanding (Compustat data item cshoq) \\\n",
    "######## divided by [beginning-of-quarter] book value of equity (Compustat data item ceqq) \n",
    "crsp_comp_edgar['MTB'] = (crsp_comp_edgar['lag_prccq']*crsp_comp_edgar['lag_cshoq'])/crsp_comp_edgar['lag_ceqq']\n",
    "\n",
    "######## LEV: Leverage, defined as [beginning-of-quarter] short term debt plus [beginning-of-quarter] long term debt \\\n",
    "######## (Compustat data item dlcq + Compustat data item dlttq) scaled by [beginning-of-quarter] total assets (Compustat data item atq)\n",
    "crsp_comp_edgar['LEV'] = (crsp_comp_edgar['lag_dlcq'] + crsp_comp_edgar['lag_dlttq'])/crsp_comp_edgar['lag_atq']\n",
    "\n",
    "# ######## AGE: log(1 + age from the first year the firm entered the CRSP dataset)\n",
    "# id_crsp_comp_text['AGE'] = np.log(1 + id_crsp_comp_text['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of obs. from utility and financial firms: 15201\n",
      "number of firm-quarters with missing SIC, SIZE, MTB, LEV or non-positive (total assets or book value of equity or common shares outstanding), or lag_prcc < 1: 9111\n",
      "number of words, 1% quantile: 131.0\n",
      "number of obs. that contain total words less than 1% threshold: 476\n",
      "TLAG 99% quantile: 16.0\n",
      "number of obs. that contain negative or larger than 99% TLAG: 466\n",
      "Number of obs. after variable screening: 47837\n"
     ]
    }
   ],
   "source": [
    "#######################################################################################\n",
    "############################### Variable Screening #####################################\n",
    "########################################################################################\n",
    "\n",
    "############## Drop financial and utility firms (SIC codes between 6000 and 6999 and between 4900 and 4999, respectively)\n",
    "del_fin = crsp_comp_edgar.loc[(crsp_comp_edgar['SIC'] >= 6000) & (crsp_comp_edgar['SIC'] <= 6999)].shape[0]\n",
    "crsp_comp_edgar = crsp_comp_edgar.loc[(crsp_comp_edgar['SIC'] < 6000) | (crsp_comp_edgar['SIC'] > 6999)] # financial\n",
    "del_ut = crsp_comp_edgar.loc[(crsp_comp_edgar['SIC'] >= 4900) & (crsp_comp_edgar['SIC'] <= 4999)].shape[0]\n",
    "crsp_comp_edgar = crsp_comp_edgar.loc[(crsp_comp_edgar['SIC'] < 4900) | (crsp_comp_edgar['SIC'] > 4999)] # utility\n",
    "print('number of obs. from utility and financial firms: ' + str(del_fin + del_ut))\n",
    "\n",
    "############## Drop files (firm-quarter) that have missing SIC, SIZE, MTB, LEV, or with non-positive total assets or book value of equity\n",
    "del_size = crsp_comp_edgar[crsp_comp_edgar['SIZE'].isnull()].shape[0]\n",
    "crsp_comp_edgar = crsp_comp_edgar[crsp_comp_edgar['SIZE'].notnull()]\n",
    "del_mtb = crsp_comp_edgar[crsp_comp_edgar['MTB'].isnull()].shape[0]\n",
    "crsp_comp_edgar = crsp_comp_edgar[crsp_comp_edgar['MTB'].notnull()]\n",
    "del_lev = crsp_comp_edgar[crsp_comp_edgar['LEV'].isnull()].shape[0]\n",
    "crsp_comp_edgar = crsp_comp_edgar[crsp_comp_edgar['LEV'].notnull()]\n",
    "del_atq = crsp_comp_edgar.loc[(crsp_comp_edgar['atq'] <= 0) | (crsp_comp_edgar['atq'].isnull())].shape[0]\n",
    "crsp_comp_edgar = crsp_comp_edgar.loc[crsp_comp_edgar['atq'] > 0]\n",
    "del_ceqq = crsp_comp_edgar.loc[(crsp_comp_edgar['ceqq'] <= 0) | (crsp_comp_edgar['ceqq'].isnull())].shape[0]\n",
    "crsp_comp_edgar = crsp_comp_edgar.loc[crsp_comp_edgar['ceqq'] > 0]\n",
    "print('number of firm-quarters with missing SIC, SIZE, MTB, LEV or non-positive (total assets or book value of equity or common shares outstanding), or lag_prcc < 1: ' \\\n",
    "      + str(del_sic + del_size + del_mtb + del_lev + del_atq + del_ceqq + del_prccq + del_cshoq))\n",
    "\n",
    "########## Drop files (firm-quarter) that contain number of words less than 1% threshold (or larger than 99% threshold)\n",
    "nwq01 = crsp_comp_edgar['nw'].quantile(.01)\n",
    "print('number of words, 1% quantile: ' + str(nwq01))\n",
    "del_word01 = crsp_comp_edgar.loc[crsp_comp_edgar['nw'] < nwq01].shape[0]\n",
    "print('number of obs. that contain total words less than 1% threshold: ' + str(del_word01))\n",
    "crsp_comp_edgar = crsp_comp_edgar.loc[crsp_comp_edgar['nw'] >= nwq01]\n",
    "\n",
    "# nwq99 = crsp_comp_edgar['nw'].quantile(.99)\n",
    "# print('number of words, 99% quantile: ' + str(nwq99))\n",
    "# del_word99 = crsp_comp_edgar.loc[crsp_comp_edgar['nw'] > nwq99].shape[0]\n",
    "# print('number of obs. that contain total words more than 99% threshold: ' + str(del_word99))\n",
    "# crsp_comp_edgar = crsp_comp_edgar.loc[crsp_comp_edgar['nw'] <= nwq99]\n",
    "\n",
    "########## Drop files (firm-quarter) that contain negative RLAG\n",
    "# Rationale to drop negative TLAG: By construction, filings with filing date prior to news release date cannot be addressing the news. \n",
    "# ANTICIPATION is not purpose of the paper.\n",
    "del_TLAG0 = crsp_comp_edgar[crsp_comp_edgar['TLAG'] < 0].shape[0]\n",
    "crsp_comp_edgar = crsp_comp_edgar[crsp_comp_edgar['TLAG'] >= 0]\n",
    "\n",
    "########## Drop files (firm-quarter) that contain larger than 99% TLAG\n",
    "tlagq99 = crsp_comp_edgar['TLAG'].quantile(.99)\n",
    "print('TLAG 99% quantile: ' + str(tlagq99))\n",
    "del_TLAG99 = crsp_comp_edgar.loc[crsp_comp_edgar['TLAG'] > tlagq99].shape[0]\n",
    "print('number of obs. that contain negative or larger than 99% TLAG: ' + str(del_TLAG99 + del_TLAG0))\n",
    "crsp_comp_edgar = crsp_comp_edgar.loc[crsp_comp_edgar['TLAG'] <= tlagq99]\n",
    "\n",
    "############## Winsorize SIZE, MTB, LEV\n",
    "###### Define a function that winsorize a variable at 1% and 99% \n",
    "def winsorize (df, colnames):\n",
    "    for col in colnames:\n",
    "        varq01 = df[col].quantile(.01)\n",
    "        varq99 = df[col].quantile(.99)\n",
    "        df[col] = df[col].clip(varq01, varq99)\n",
    "    return df\n",
    "\n",
    "crsp_comp_edgar = winsorize(crsp_comp_edgar, ['SIZE', 'MTB', 'LEV'])\n",
    "\n",
    "############## Inspect sample size after variable screening\n",
    "print('Number of obs. after variable screening: ' + str(crsp_comp_edgar.shape[0]))\n",
    "\n",
    "############## Manual correction for one observation (with nitem=0): https://www.sec.gov/Archives/edgar/data/1164727/000089109204004189/0000891092-04-004189-index.htm\n",
    "crsp_comp_edgar.loc[crsp_comp_edgar['nitem'] == 0, 'item_5'] = 1\n",
    "crsp_comp_edgar.loc[crsp_comp_edgar['nitem'] == 0, 'item_7'] = 1\n",
    "crsp_comp_edgar.loc[crsp_comp_edgar['nitem'] == 0, 'nitem'] = 2\n",
    "\n",
    "############# Save processed CRSP_COMP_EDGAR to .csv file\n",
    "crsp_comp_edgar.to_csv('..\\\\filings\\\\crsp_comp_edgar_'+ obj_type + '_no_match.csv', index = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
